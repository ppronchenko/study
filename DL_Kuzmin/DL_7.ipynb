{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Практика лекция 7",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiM6kiuahjau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8egpYGSSh3p3",
        "colab_type": "code",
        "outputId": "62a6dcc2-343c-4a87-fca8-509319947106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        }
      },
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>episode_id</th>\n",
              "      <th>number</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>timestamp_in_ms</th>\n",
              "      <th>speaking_line</th>\n",
              "      <th>character_id</th>\n",
              "      <th>location_id</th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>raw_location_text</th>\n",
              "      <th>spoken_words</th>\n",
              "      <th>normalized_text</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>128202</td>\n",
              "      <td>456</td>\n",
              "      <td>1</td>\n",
              "      <td>Homer Simpson: (CHUCKLES) Thanks to our new G....</td>\n",
              "      <td>92000</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Homer Simpson</td>\n",
              "      <td>Homer's Car</td>\n",
              "      <td>Thanks to our new G.P.S., I'll have you at sch...</td>\n",
              "      <td>thanks to our new gps ill have you at school i...</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>128204</td>\n",
              "      <td>456</td>\n",
              "      <td>3</td>\n",
              "      <td>Homer Simpson: (ANGUISHED MOAN) Meters?</td>\n",
              "      <td>99000</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Homer Simpson</td>\n",
              "      <td>Homer's Car</td>\n",
              "      <td>Meters?</td>\n",
              "      <td>meters</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>128205</td>\n",
              "      <td>456</td>\n",
              "      <td>4</td>\n",
              "      <td>Lisa Simpson: Dad, a meter is three inches lon...</td>\n",
              "      <td>100000</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Homer's Car</td>\n",
              "      <td>Dad, a meter is three inches longer than a yar...</td>\n",
              "      <td>dad a meter is three inches longer than a yard...</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>128207</td>\n",
              "      <td>456</td>\n",
              "      <td>6</td>\n",
              "      <td>Bart Simpson: Dad, no! That takes us into a co...</td>\n",
              "      <td>113000</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Bart Simpson</td>\n",
              "      <td>Homer's Car</td>\n",
              "      <td>Dad, no! That takes us into a construction site!</td>\n",
              "      <td>dad no that takes us into a construction site</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>128208</td>\n",
              "      <td>456</td>\n",
              "      <td>7</td>\n",
              "      <td>Homer Simpson: Stupid kid. Thinks he's smarter...</td>\n",
              "      <td>115000</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Homer Simpson</td>\n",
              "      <td>Homer's Car</td>\n",
              "      <td>Stupid kid. Thinks he's smarter than a computer.</td>\n",
              "      <td>stupid kid thinks hes smarter than a computer</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  word_count\n",
              "0           0  ...        13.0\n",
              "1           1  ...         1.0\n",
              "2           2  ...        22.0\n",
              "3           3  ...         9.0\n",
              "4           4  ...         8.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipFlalWGiEkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[df['raw_character_text'].isin(('Lisa Simpson', 'Bart Simpson'))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypIerp3TiVU5",
        "colab_type": "code",
        "outputId": "ff7c5839-af79-4fad-9c47-4b07047b3639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>episode_id</th>\n",
              "      <th>number</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>timestamp_in_ms</th>\n",
              "      <th>speaking_line</th>\n",
              "      <th>character_id</th>\n",
              "      <th>location_id</th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>raw_location_text</th>\n",
              "      <th>spoken_words</th>\n",
              "      <th>normalized_text</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>128205</td>\n",
              "      <td>456</td>\n",
              "      <td>4</td>\n",
              "      <td>Lisa Simpson: Dad, a meter is three inches lon...</td>\n",
              "      <td>100000</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Homer's Car</td>\n",
              "      <td>Dad, a meter is three inches longer than a yar...</td>\n",
              "      <td>dad a meter is three inches longer than a yard...</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>128207</td>\n",
              "      <td>456</td>\n",
              "      <td>6</td>\n",
              "      <td>Bart Simpson: Dad, no! That takes us into a co...</td>\n",
              "      <td>113000</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Bart Simpson</td>\n",
              "      <td>Homer's Car</td>\n",
              "      <td>Dad, no! That takes us into a construction site!</td>\n",
              "      <td>dad no that takes us into a construction site</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>128214</td>\n",
              "      <td>456</td>\n",
              "      <td>13</td>\n",
              "      <td>Bart Simpson: Thanks for the ride! / Bye, Dad!</td>\n",
              "      <td>144000</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Bart Simpson</td>\n",
              "      <td>Homer's Car</td>\n",
              "      <td>Thanks for the ride! / Bye, Dad!</td>\n",
              "      <td>thanks for the ride bye dad</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>128222</td>\n",
              "      <td>456</td>\n",
              "      <td>21</td>\n",
              "      <td>Bart Simpson: Where's Mrs. K.?</td>\n",
              "      <td>151000</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "      <td>573.0</td>\n",
              "      <td>Bart Simpson</td>\n",
              "      <td>Mrs. Krabappel's Classroom</td>\n",
              "      <td>Where's Mrs. K.?</td>\n",
              "      <td>wheres mrs k</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>128224</td>\n",
              "      <td>456</td>\n",
              "      <td>23</td>\n",
              "      <td>Bart Simpson: So, who's gonna take her place? ...</td>\n",
              "      <td>182000</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "      <td>573.0</td>\n",
              "      <td>Bart Simpson</td>\n",
              "      <td>Mrs. Krabappel's Classroom</td>\n",
              "      <td>So, who's gonna take her place? Me, I hope?</td>\n",
              "      <td>so whos gonna take her place me i hope</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  ...  word_count\n",
              "2            2  ...        22.0\n",
              "3            3  ...         9.0\n",
              "7            7  ...         6.0\n",
              "9            9  ...         3.0\n",
              "11          11  ...         9.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TbgsIVPiYNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[~df['normalized_text'].isna()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpp2Y8Dfiflp",
        "colab_type": "code",
        "outputId": "941ae8be-6f14-453e-f803-5b7c4c579241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>episode_id</th>\n",
              "      <th>number</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>timestamp_in_ms</th>\n",
              "      <th>speaking_line</th>\n",
              "      <th>character_id</th>\n",
              "      <th>location_id</th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>raw_location_text</th>\n",
              "      <th>spoken_words</th>\n",
              "      <th>normalized_text</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>128205</td>\n",
              "      <td>456</td>\n",
              "      <td>4</td>\n",
              "      <td>Lisa Simpson: Dad, a meter is three inches lon...</td>\n",
              "      <td>100000</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Homer's Car</td>\n",
              "      <td>Dad, a meter is three inches longer than a yar...</td>\n",
              "      <td>dad a meter is three inches longer than a yard...</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>128207</td>\n",
              "      <td>456</td>\n",
              "      <td>6</td>\n",
              "      <td>Bart Simpson: Dad, no! That takes us into a co...</td>\n",
              "      <td>113000</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Bart Simpson</td>\n",
              "      <td>Homer's Car</td>\n",
              "      <td>Dad, no! That takes us into a construction site!</td>\n",
              "      <td>dad no that takes us into a construction site</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>128214</td>\n",
              "      <td>456</td>\n",
              "      <td>13</td>\n",
              "      <td>Bart Simpson: Thanks for the ride! / Bye, Dad!</td>\n",
              "      <td>144000</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "      <td>29.0</td>\n",
              "      <td>Bart Simpson</td>\n",
              "      <td>Homer's Car</td>\n",
              "      <td>Thanks for the ride! / Bye, Dad!</td>\n",
              "      <td>thanks for the ride bye dad</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>128222</td>\n",
              "      <td>456</td>\n",
              "      <td>21</td>\n",
              "      <td>Bart Simpson: Where's Mrs. K.?</td>\n",
              "      <td>151000</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "      <td>573.0</td>\n",
              "      <td>Bart Simpson</td>\n",
              "      <td>Mrs. Krabappel's Classroom</td>\n",
              "      <td>Where's Mrs. K.?</td>\n",
              "      <td>wheres mrs k</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>128224</td>\n",
              "      <td>456</td>\n",
              "      <td>23</td>\n",
              "      <td>Bart Simpson: So, who's gonna take her place? ...</td>\n",
              "      <td>182000</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "      <td>573.0</td>\n",
              "      <td>Bart Simpson</td>\n",
              "      <td>Mrs. Krabappel's Classroom</td>\n",
              "      <td>So, who's gonna take her place? Me, I hope?</td>\n",
              "      <td>so whos gonna take her place me i hope</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  ...  word_count\n",
              "2            2  ...        22.0\n",
              "3            3  ...         9.0\n",
              "7            7  ...         6.0\n",
              "9            9  ...         3.0\n",
              "11          11  ...         9.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbecqH8Wigba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = df['normalized_text'].tolist(), df['raw_character_text'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS5Wi-X_izKq",
        "colab_type": "text"
      },
      "source": [
        "## Работаем с выборкой"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-N2gPx4iwZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvfc3NIji-Dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "l = LabelEncoder()\n",
        "y_train = l.fit_transform(y_train)\n",
        "y_test = l.transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7VV74jCjPmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = ' '.join(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElShuPdrjk9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ALL_WORDS = set(text.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2jCWVvVjoEq",
        "colab_type": "code",
        "outputId": "918e8986-4661-4ad5-ff45-4c3ddd030379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(ALL_WORDS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pyr2SHVjreX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcSwbm6rj7kg",
        "colab_type": "code",
        "outputId": "0cb5bdb2-8a4c-4e58-faab-be9101e4de0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "c = Counter(text.split(' '))\n",
        "c.most_common(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 4977),\n",
              " ('i', 4911),\n",
              " ('you', 4780),\n",
              " ('a', 4010),\n",
              " ('to', 3425),\n",
              " ('and', 2297),\n",
              " ('it', 1955),\n",
              " ('of', 1887),\n",
              " ('is', 1657),\n",
              " ('dad', 1569)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRIiZXWcj-gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORDS_COUNT = 2000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERhxSnUBkF_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ALL_WORDS = set([w for w, _ in c.most_common(WORDS_COUNT)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58-maQh9kNjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDEX_TO_WORD = ['<pad>', '<miss>'] + list(ALL_WORDS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-m20R_-kPLX",
        "colab_type": "code",
        "outputId": "e187f23c-78da-446a-979e-3fec91477203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(INDEX_TO_WORD)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs_BNWufknpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORD_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_WORD)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KDk17yNkt7l",
        "colab_type": "code",
        "outputId": "a821f4f8-976d-40bc-beee-5719cc3c3f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "INDEX_TO_WORD[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad>',\n",
              " '<miss>',\n",
              " 'ugh',\n",
              " 'shelbyville',\n",
              " 'surprise',\n",
              " 'truly',\n",
              " 'people',\n",
              " 'hard',\n",
              " 'between',\n",
              " 'beg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpeKwLpjk8hO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7wKe91YlGa7",
        "colab_type": "code",
        "outputId": "ab662c5e-7e80-42c4-df0f-12f948abe8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "plt.hist([len(s.split(' ')) for s in X_train], bins=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.949e+03, 1.405e+03, 3.032e+03, 1.466e+03, 2.560e+03, 9.540e+02,\n",
              "        1.625e+03, 7.260e+02, 1.165e+03, 4.440e+02, 6.920e+02, 3.000e+02,\n",
              "        4.780e+02, 1.680e+02, 2.810e+02, 1.270e+02, 1.650e+02, 6.700e+01,\n",
              "        9.900e+01, 4.000e+01, 7.200e+01, 2.800e+01, 3.800e+01, 1.800e+01,\n",
              "        1.400e+01, 2.200e+01, 1.200e+01, 1.600e+01, 9.000e+00, 8.000e+00,\n",
              "        2.000e+00, 1.000e+01, 2.000e+00, 5.000e+00, 1.000e+00, 3.000e+00,\n",
              "        1.000e+00, 0.000e+00, 2.000e+00, 4.000e+00, 3.000e+00, 1.000e+00,\n",
              "        0.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 0.000e+00,\n",
              "        0.000e+00, 2.000e+00]),\n",
              " array([ 1.  ,  2.48,  3.96,  5.44,  6.92,  8.4 ,  9.88, 11.36, 12.84,\n",
              "        14.32, 15.8 , 17.28, 18.76, 20.24, 21.72, 23.2 , 24.68, 26.16,\n",
              "        27.64, 29.12, 30.6 , 32.08, 33.56, 35.04, 36.52, 38.  , 39.48,\n",
              "        40.96, 42.44, 43.92, 45.4 , 46.88, 48.36, 49.84, 51.32, 52.8 ,\n",
              "        54.28, 55.76, 57.24, 58.72, 60.2 , 61.68, 63.16, 64.64, 66.12,\n",
              "        67.6 , 69.08, 70.56, 72.04, 73.52, 75.  ]),\n",
              " <a list of 50 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1BFDX5I68v8AGlzLSZ0LC3EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTka2Rlbk5T_",
        "colab_type": "text"
      },
      "source": [
        "## Формируем датасеты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deFc2d0LkvWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5L3M7lale9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMfvwsealjjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = torch.zeros((len(X_train), MAX_LEN), dtype=int)\n",
        "test_data = torch.zeros((len(X_test), MAX_LEN), dtype=int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O5YSvEClvUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X_train)):\n",
        "  for j, w in enumerate(X_train[i].split(' ')):\n",
        "    if j >= MAX_LEN:\n",
        "      break\n",
        "    train_data[i, j] = WORD_TO_INDEX.get(w, WORD_TO_INDEX['<miss>'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ74aPlDmK03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X_test)):\n",
        "  for j, w in enumerate(X_test[i].split(' ')):\n",
        "    if j >= MAX_LEN:\n",
        "      break\n",
        "    test_data[i, j] = WORD_TO_INDEX.get(w, WORD_TO_INDEX['<miss>'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsHWd0R8mdQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(train_data, torch.LongTensor(y_train))\n",
        "test_dataset = torch.utils.data.TensorDataset(test_data, torch.LongTensor(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR1vlCvDm9kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9ucwCPRm_W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = torch.utils.data.DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n",
        "test = torch.utils.data.DataLoader(test_dataset, BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr9Vdo2enQJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmcekaNLndKQ",
        "colab_type": "text"
      },
      "source": [
        "## Модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIiRVXh4nUn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1FrjAN6nryJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VanilaModel(nn.Module):\n",
        "  def __init__(self, dict_size, embed_size, num_hiddens, num_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_hiddens = num_hiddens\n",
        "    self.embed = nn.Embedding(dict_size, embed_size)\n",
        "    self.rnn = nn.RNN(embed_size, num_hiddens, batch_first=True)\n",
        "    self.output = nn.Linear(num_hiddens, num_classes)\n",
        "\n",
        "  def forward(self, X):\n",
        "    output = self.embed(X)\n",
        "    y, s = self.rnn(output)\n",
        "    return self.output(s[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXdEK6o2q9-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRUModel(nn.Module):\n",
        "  def __init__(self, dict_size, embed_size, num_hiddens, num_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_hiddens = num_hiddens\n",
        "    self.embed = nn.Embedding(dict_size, embed_size)\n",
        "    self.rnn = nn.GRU(embed_size, num_hiddens, batch_first=True)\n",
        "    self.output = nn.Linear(num_hiddens, num_classes)\n",
        "\n",
        "  def forward(self, X):\n",
        "    output = self.embed(X)\n",
        "    y, s = self.rnn(output)\n",
        "    return self.output(s[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHLlqaozrQAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self, dict_size, embed_size, num_hiddens, num_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_hiddens = num_hiddens\n",
        "    self.embed = nn.Embedding(dict_size, embed_size)\n",
        "    self.rnn = nn.LSTM(embed_size, num_hiddens, batch_first=True)\n",
        "    self.output = nn.Linear(num_hiddens, num_classes)\n",
        "\n",
        "  def forward(self, X):\n",
        "    output = self.embed(X)\n",
        "    y, s = self.rnn(output)\n",
        "    return self.output(s[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp--X-EksOGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UberModel(nn.Module):\n",
        "  def __init__(self, dict_size, embed_size, num_hiddens, num_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_hiddens = num_hiddens\n",
        "    self.embed = nn.Embedding(dict_size, embed_size)\n",
        "    self.rnn = nn.GRU(embed_size, num_hiddens, batch_first=True, num_layers=2)\n",
        "    self.hidden = nn.Linear(num_hiddens, num_classes)\n",
        "\n",
        "  def forward(self, X):\n",
        "    output = self.embed(X)\n",
        "    y, s = self.rnn(output)\n",
        "    h = self.hidden(s[0])\n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B08c2WiGomkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = VanilaModel(len(INDEX_TO_WORD), 300, 256, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vy3QFeQotYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for X, y in train:\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l90ZQIxowFz",
        "colab_type": "code",
        "outputId": "f6b387f4-e8fb-49ec-ba85-1125847b563d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model(X).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y38AMZZ_o5nu",
        "colab_type": "text"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QybAScnwpwMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJU4Cz3KoxdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_acc(model, dataset, dev):\n",
        "  loss = nn.CrossEntropyLoss(reduction='sum')\n",
        "  loss_acc, passed, correct = 0., 0, 0\n",
        "  for X, y in dataset:\n",
        "    X = X.to(dev)\n",
        "    y = y.to(dev)\n",
        "\n",
        "    output = model(X)\n",
        "    l = loss(output, y)\n",
        "\n",
        "    loss_acc += l.item()\n",
        "    correct += (output.argmax(dim=1) == y).sum().item()\n",
        "    passed += len(y)\n",
        "\n",
        "  return loss_acc / passed, correct / passed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLsMCVb_pcN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, train_dl, test_dl, trainer, dev, num_epochs=25):\n",
        "  loss = nn.CrossEntropyLoss(reduction='sum')\n",
        "  for ep in range(num_epochs):\n",
        "    ep_start, tloss_acc, tpassed, tcorrect = time.time(), 0., 0, 0\n",
        "    for X, y in train_dl:\n",
        "      X, y = X.to(dev), y.to(dev)\n",
        "      trainer.zero_grad()\n",
        "\n",
        "      output = model(X)\n",
        "      l = loss(output, y)\n",
        "      l.backward()\n",
        "      trainer.step()\n",
        "\n",
        "      tloss_acc += l.item()\n",
        "      tcorrect += (output.argmax(dim=1) == y).sum().item()\n",
        "      tpassed += len(y)\n",
        "    \n",
        "    test_loss, test_acc = validate_acc(model, test_dl, dev)\n",
        "\n",
        "    print('Epoch {}. Taked {:.3f} sec. Train loss: {:.3f}, Train acc {:.3f}, Test  Loss {:.3f}, Test Acc {:.3f}'.format(\n",
        "        ep, time.time() - ep_start, tloss_acc / tpassed, tcorrect / tpassed, test_loss, test_acc\n",
        "    ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1Gbv0w0qjxq",
        "colab_type": "text"
      },
      "source": [
        "## Эксперимент"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYJEuJVyqgE2",
        "colab_type": "code",
        "outputId": "cf8a539e-d10c-46ad-ce85-f779fc9c6e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "model = VanilaModel(len(INDEX_TO_WORD), 300, 256, 2).to(dev)\n",
        "trainer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "train_model(model, train, test, trainer, dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Taked 1.364 sec. Train loss: 69.529, Train acc 0.508, Test  Loss 30.915, Test Acc 0.563\n",
            "Epoch 1. Taked 1.332 sec. Train loss: 73.412, Train acc 0.500, Test  Loss 34.554, Test Acc 0.560\n",
            "Epoch 2. Taked 1.292 sec. Train loss: 72.868, Train acc 0.498, Test  Loss 57.887, Test Acc 0.557\n",
            "Epoch 3. Taked 1.304 sec. Train loss: 71.748, Train acc 0.503, Test  Loss 66.389, Test Acc 0.444\n",
            "Epoch 4. Taked 1.273 sec. Train loss: 70.431, Train acc 0.510, Test  Loss 44.452, Test Acc 0.556\n",
            "Epoch 5. Taked 1.277 sec. Train loss: 70.772, Train acc 0.508, Test  Loss 9.375, Test Acc 0.560\n",
            "Epoch 6. Taked 1.277 sec. Train loss: 72.025, Train acc 0.505, Test  Loss 16.717, Test Acc 0.559\n",
            "Epoch 7. Taked 1.302 sec. Train loss: 71.007, Train acc 0.509, Test  Loss 43.482, Test Acc 0.559\n",
            "Epoch 8. Taked 1.269 sec. Train loss: 68.737, Train acc 0.515, Test  Loss 42.639, Test Acc 0.554\n",
            "Epoch 9. Taked 1.278 sec. Train loss: 71.305, Train acc 0.507, Test  Loss 81.320, Test Acc 0.559\n",
            "Epoch 10. Taked 1.299 sec. Train loss: 70.063, Train acc 0.511, Test  Loss 65.940, Test Acc 0.439\n",
            "Epoch 11. Taked 1.306 sec. Train loss: 72.286, Train acc 0.508, Test  Loss 16.704, Test Acc 0.558\n",
            "Epoch 12. Taked 1.311 sec. Train loss: 71.981, Train acc 0.507, Test  Loss 34.016, Test Acc 0.561\n",
            "Epoch 13. Taked 1.299 sec. Train loss: 71.445, Train acc 0.505, Test  Loss 55.896, Test Acc 0.440\n",
            "Epoch 14. Taked 1.279 sec. Train loss: 72.765, Train acc 0.505, Test  Loss 39.697, Test Acc 0.442\n",
            "Epoch 15. Taked 1.258 sec. Train loss: 71.290, Train acc 0.507, Test  Loss 31.573, Test Acc 0.557\n",
            "Epoch 16. Taked 1.260 sec. Train loss: 70.159, Train acc 0.508, Test  Loss 44.962, Test Acc 0.555\n",
            "Epoch 17. Taked 1.268 sec. Train loss: 69.922, Train acc 0.513, Test  Loss 22.635, Test Acc 0.560\n",
            "Epoch 18. Taked 1.260 sec. Train loss: 71.649, Train acc 0.505, Test  Loss 63.962, Test Acc 0.559\n",
            "Epoch 19. Taked 1.252 sec. Train loss: 70.494, Train acc 0.511, Test  Loss 43.999, Test Acc 0.556\n",
            "Epoch 20. Taked 1.275 sec. Train loss: 69.215, Train acc 0.514, Test  Loss 74.359, Test Acc 0.558\n",
            "Epoch 21. Taked 1.263 sec. Train loss: 70.147, Train acc 0.512, Test  Loss 1.411, Test Acc 0.555\n",
            "Epoch 22. Taked 1.279 sec. Train loss: 68.148, Train acc 0.515, Test  Loss 18.890, Test Acc 0.442\n",
            "Epoch 23. Taked 1.274 sec. Train loss: 70.862, Train acc 0.509, Test  Loss 29.468, Test Acc 0.562\n",
            "Epoch 24. Taked 1.244 sec. Train loss: 71.429, Train acc 0.508, Test  Loss 46.703, Test Acc 0.562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NesJuQOqqxNW",
        "colab_type": "code",
        "outputId": "6908872c-e899-447d-ebbd-c3210bb237ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "model = GRUModel(len(INDEX_TO_WORD), 300, 256, 2).to(dev)\n",
        "trainer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "train_model(model, train, test, trainer, dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Taked 1.730 sec. Train loss: 13.687, Train acc 0.506, Test  Loss 3.895, Test Acc 0.575\n",
            "Epoch 1. Taked 1.609 sec. Train loss: 7.067, Train acc 0.532, Test  Loss 2.154, Test Acc 0.572\n",
            "Epoch 2. Taked 1.626 sec. Train loss: 4.711, Train acc 0.571, Test  Loss 2.741, Test Acc 0.564\n",
            "Epoch 3. Taked 1.597 sec. Train loss: 3.983, Train acc 0.604, Test  Loss 2.227, Test Acc 0.583\n",
            "Epoch 4. Taked 1.607 sec. Train loss: 3.329, Train acc 0.636, Test  Loss 2.934, Test Acc 0.583\n",
            "Epoch 5. Taked 1.612 sec. Train loss: 2.480, Train acc 0.680, Test  Loss 2.652, Test Acc 0.594\n",
            "Epoch 6. Taked 1.592 sec. Train loss: 1.834, Train acc 0.734, Test  Loss 2.827, Test Acc 0.596\n",
            "Epoch 7. Taked 1.609 sec. Train loss: 1.196, Train acc 0.779, Test  Loss 3.139, Test Acc 0.612\n",
            "Epoch 8. Taked 1.601 sec. Train loss: 0.821, Train acc 0.822, Test  Loss 2.577, Test Acc 0.600\n",
            "Epoch 9. Taked 1.611 sec. Train loss: 0.521, Train acc 0.861, Test  Loss 2.647, Test Acc 0.602\n",
            "Epoch 10. Taked 1.641 sec. Train loss: 0.296, Train acc 0.903, Test  Loss 2.631, Test Acc 0.600\n",
            "Epoch 11. Taked 1.610 sec. Train loss: 0.203, Train acc 0.924, Test  Loss 2.364, Test Acc 0.598\n",
            "Epoch 12. Taked 1.621 sec. Train loss: 0.158, Train acc 0.935, Test  Loss 2.366, Test Acc 0.594\n",
            "Epoch 13. Taked 1.594 sec. Train loss: 0.138, Train acc 0.939, Test  Loss 2.476, Test Acc 0.594\n",
            "Epoch 14. Taked 1.598 sec. Train loss: 0.132, Train acc 0.945, Test  Loss 2.420, Test Acc 0.586\n",
            "Epoch 15. Taked 1.618 sec. Train loss: 0.132, Train acc 0.943, Test  Loss 2.443, Test Acc 0.595\n",
            "Epoch 16. Taked 1.603 sec. Train loss: 0.135, Train acc 0.941, Test  Loss 2.459, Test Acc 0.585\n",
            "Epoch 17. Taked 1.628 sec. Train loss: 0.128, Train acc 0.943, Test  Loss 2.569, Test Acc 0.600\n",
            "Epoch 18. Taked 1.594 sec. Train loss: 0.129, Train acc 0.943, Test  Loss 2.507, Test Acc 0.587\n",
            "Epoch 19. Taked 1.592 sec. Train loss: 0.118, Train acc 0.945, Test  Loss 2.493, Test Acc 0.590\n",
            "Epoch 20. Taked 1.581 sec. Train loss: 0.116, Train acc 0.945, Test  Loss 2.491, Test Acc 0.584\n",
            "Epoch 21. Taked 1.590 sec. Train loss: 0.121, Train acc 0.946, Test  Loss 2.505, Test Acc 0.576\n",
            "Epoch 22. Taked 1.603 sec. Train loss: 0.114, Train acc 0.946, Test  Loss 2.492, Test Acc 0.595\n",
            "Epoch 23. Taked 1.616 sec. Train loss: 0.113, Train acc 0.947, Test  Loss 2.582, Test Acc 0.597\n",
            "Epoch 24. Taked 1.618 sec. Train loss: 0.112, Train acc 0.947, Test  Loss 2.576, Test Acc 0.595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm668AZ-rCoW",
        "colab_type": "code",
        "outputId": "68f513fd-7a2f-431c-b6f6-82751a6b1da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "model = LSTMModel(len(INDEX_TO_WORD), 300, 256, 2).to(dev)\n",
        "trainer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "train_model(model, train, test, trainer, dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Taked 1.949 sec. Train loss: 0.908, Train acc 0.523, Test  Loss 0.690, Test Acc 0.557\n",
            "Epoch 1. Taked 1.782 sec. Train loss: 0.679, Train acc 0.560, Test  Loss 0.685, Test Acc 0.573\n",
            "Epoch 2. Taked 1.805 sec. Train loss: 0.654, Train acc 0.610, Test  Loss 0.676, Test Acc 0.597\n",
            "Epoch 3. Taked 1.813 sec. Train loss: 0.632, Train acc 0.635, Test  Loss 0.670, Test Acc 0.611\n",
            "Epoch 4. Taked 1.776 sec. Train loss: 0.615, Train acc 0.657, Test  Loss 0.684, Test Acc 0.601\n",
            "Epoch 5. Taked 1.797 sec. Train loss: 0.600, Train acc 0.663, Test  Loss 0.689, Test Acc 0.615\n",
            "Epoch 6. Taked 1.786 sec. Train loss: 0.587, Train acc 0.671, Test  Loss 0.703, Test Acc 0.595\n",
            "Epoch 7. Taked 1.794 sec. Train loss: 0.572, Train acc 0.684, Test  Loss 0.701, Test Acc 0.599\n",
            "Epoch 8. Taked 1.787 sec. Train loss: 0.557, Train acc 0.695, Test  Loss 0.721, Test Acc 0.613\n",
            "Epoch 9. Taked 1.767 sec. Train loss: 0.544, Train acc 0.707, Test  Loss 0.718, Test Acc 0.618\n",
            "Epoch 10. Taked 1.781 sec. Train loss: 0.533, Train acc 0.719, Test  Loss 0.729, Test Acc 0.615\n",
            "Epoch 11. Taked 1.780 sec. Train loss: 0.521, Train acc 0.728, Test  Loss 0.737, Test Acc 0.617\n",
            "Epoch 12. Taked 1.759 sec. Train loss: 0.507, Train acc 0.736, Test  Loss 0.754, Test Acc 0.608\n",
            "Epoch 13. Taked 1.789 sec. Train loss: 0.491, Train acc 0.748, Test  Loss 0.782, Test Acc 0.613\n",
            "Epoch 14. Taked 1.794 sec. Train loss: 0.477, Train acc 0.760, Test  Loss 0.779, Test Acc 0.616\n",
            "Epoch 15. Taked 1.777 sec. Train loss: 0.458, Train acc 0.771, Test  Loss 0.826, Test Acc 0.608\n",
            "Epoch 16. Taked 1.782 sec. Train loss: 0.443, Train acc 0.779, Test  Loss 0.825, Test Acc 0.612\n",
            "Epoch 17. Taked 1.772 sec. Train loss: 0.423, Train acc 0.791, Test  Loss 0.853, Test Acc 0.620\n",
            "Epoch 18. Taked 1.769 sec. Train loss: 0.409, Train acc 0.801, Test  Loss 0.895, Test Acc 0.598\n",
            "Epoch 19. Taked 1.773 sec. Train loss: 0.385, Train acc 0.815, Test  Loss 0.910, Test Acc 0.606\n",
            "Epoch 20. Taked 1.764 sec. Train loss: 0.371, Train acc 0.820, Test  Loss 0.950, Test Acc 0.599\n",
            "Epoch 21. Taked 1.770 sec. Train loss: 0.364, Train acc 0.825, Test  Loss 0.980, Test Acc 0.594\n",
            "Epoch 22. Taked 1.789 sec. Train loss: 0.341, Train acc 0.838, Test  Loss 0.988, Test Acc 0.604\n",
            "Epoch 23. Taked 1.799 sec. Train loss: 0.322, Train acc 0.851, Test  Loss 1.045, Test Acc 0.596\n",
            "Epoch 24. Taked 1.776 sec. Train loss: 0.311, Train acc 0.856, Test  Loss 1.077, Test Acc 0.588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0ZVolDsrVbR",
        "colab_type": "code",
        "outputId": "7477f2a6-3906-49ab-b4a4-e5f0bd057621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "model = UberModel(len(INDEX_TO_WORD), 150, 128, 2).to(dev)\n",
        "trainer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "train_model(model, train, test, trainer, dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Taked 1.433 sec. Train loss: 5.563, Train acc 0.511, Test  Loss 1.361, Test Acc 0.559\n",
            "Epoch 1. Taked 1.284 sec. Train loss: 3.488, Train acc 0.513, Test  Loss 1.092, Test Acc 0.562\n",
            "Epoch 2. Taked 1.299 sec. Train loss: 2.575, Train acc 0.538, Test  Loss 1.340, Test Acc 0.574\n",
            "Epoch 3. Taked 1.260 sec. Train loss: 2.206, Train acc 0.554, Test  Loss 1.165, Test Acc 0.588\n",
            "Epoch 4. Taked 1.255 sec. Train loss: 1.861, Train acc 0.575, Test  Loss 1.166, Test Acc 0.601\n",
            "Epoch 5. Taked 1.262 sec. Train loss: 1.576, Train acc 0.613, Test  Loss 1.135, Test Acc 0.588\n",
            "Epoch 6. Taked 1.251 sec. Train loss: 1.377, Train acc 0.639, Test  Loss 1.381, Test Acc 0.603\n",
            "Epoch 7. Taked 1.262 sec. Train loss: 1.198, Train acc 0.675, Test  Loss 1.267, Test Acc 0.593\n",
            "Epoch 8. Taked 1.257 sec. Train loss: 0.881, Train acc 0.725, Test  Loss 1.262, Test Acc 0.600\n",
            "Epoch 9. Taked 1.262 sec. Train loss: 0.688, Train acc 0.766, Test  Loss 1.325, Test Acc 0.598\n",
            "Epoch 10. Taked 1.274 sec. Train loss: 0.480, Train acc 0.815, Test  Loss 1.378, Test Acc 0.603\n",
            "Epoch 11. Taked 1.272 sec. Train loss: 0.307, Train acc 0.867, Test  Loss 1.527, Test Acc 0.574\n",
            "Epoch 12. Taked 1.253 sec. Train loss: 0.227, Train acc 0.900, Test  Loss 1.538, Test Acc 0.600\n",
            "Epoch 13. Taked 1.258 sec. Train loss: 0.181, Train acc 0.918, Test  Loss 1.652, Test Acc 0.596\n",
            "Epoch 14. Taked 1.253 sec. Train loss: 0.160, Train acc 0.927, Test  Loss 1.754, Test Acc 0.593\n",
            "Epoch 15. Taked 1.254 sec. Train loss: 0.141, Train acc 0.936, Test  Loss 1.836, Test Acc 0.598\n",
            "Epoch 16. Taked 1.284 sec. Train loss: 0.130, Train acc 0.939, Test  Loss 1.923, Test Acc 0.583\n",
            "Epoch 17. Taked 1.293 sec. Train loss: 0.123, Train acc 0.940, Test  Loss 1.903, Test Acc 0.593\n",
            "Epoch 18. Taked 1.259 sec. Train loss: 0.121, Train acc 0.943, Test  Loss 1.967, Test Acc 0.597\n",
            "Epoch 19. Taked 1.260 sec. Train loss: 0.118, Train acc 0.943, Test  Loss 1.974, Test Acc 0.590\n",
            "Epoch 20. Taked 1.258 sec. Train loss: 0.113, Train acc 0.944, Test  Loss 2.025, Test Acc 0.598\n",
            "Epoch 21. Taked 1.289 sec. Train loss: 0.109, Train acc 0.946, Test  Loss 2.010, Test Acc 0.601\n",
            "Epoch 22. Taked 1.264 sec. Train loss: 0.107, Train acc 0.943, Test  Loss 2.054, Test Acc 0.596\n",
            "Epoch 23. Taked 1.257 sec. Train loss: 0.107, Train acc 0.946, Test  Loss 2.061, Test Acc 0.583\n",
            "Epoch 24. Taked 1.244 sec. Train loss: 0.104, Train acc 0.946, Test  Loss 2.122, Test Acc 0.604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDtlkpRmsld-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}