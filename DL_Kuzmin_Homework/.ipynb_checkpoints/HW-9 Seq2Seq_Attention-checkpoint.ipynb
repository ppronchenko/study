{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YlRH3mQM9tf"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIEGXF8oM9tt"
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -O ../../study_data/DL_9_HW/eng-rus.zip https://www.manythings.org/anki/rus-eng.zip\n",
    "#!unzip ../../study_data/DL_9_HW/eng-rus.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Info **\n",
      "\n",
      "Check for newest version here:\n",
      "  http://www.manythings.org/anki/\n",
      "Date of this file:\n",
      "  2020-03-15\n",
      "\n",
      "This data is from the sentences_detailed.csv file from tatoeba.org.\n",
      "http://tatoeba.org/files/downloads/sentences_detailed.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!head ../../study_data/DL_9_HW/_about.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom said, \"You can kiss your girlfriend goodbye if you don't kiss her goodbye,\" which meant, \"If you don't kiss your girlfriend goodbye, then you'll never see her again.\"\t«Можешь попрощаться со своей подружкой, если ты с ней не попрощаешься», — сказал Том, что означало «если ты не попрощаешься со своей подружкой, то больше ты её никогда не увидишь».\tCC-BY 2.0 (France) Attribution: tatoeba.org #1065032 (CK) & #4435211 (sharptoothed)\n",
      "The more countries a language is spoken in, the less important it is to sound like a native speaker, since speakers of that language are accustomed to hearing various dialects.\tЧем в большем количестве стран используется тот или иной язык, тем менее важно иметь такое же произношение, как у его носителей, так как носители этого языка привыкли к звучанию различных акцентов.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954354 (CK) & #4465953 (Wezel)\n",
      "A mistake young people often make is to start learning too many languages at the same time, as they underestimate the difficulties and overestimate their own ability to learn them.\tОшибка, которую часто делают молодые, — начинают учить слишком много языков одновременно: они недооценивают трудности и переоценивают свои способности к изучению.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2783162 (catcher) & #5118905 (Wezel)\n",
      "We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (CO) & #6390439 (odexed)\n",
      "I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (CO) & #6390123 (odexed)\n",
      "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (CO) & #5968115 (odexed)\n",
      "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n",
      "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (CO) & #4509418 (odexed)\n",
      "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
      "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"
     ]
    }
   ],
   "source": [
    "!tail ../../study_data/DL_9_HW/rus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyNnJyruM9t1"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXKs8j4bM9t6"
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-ZА-Яа-яёЁ.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8T4VxZeM9t-"
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('../../study_data/DL_9_HW/rus.txt').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBOwgEBdM9uB"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "        \n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5168,
     "status": "ok",
     "timestamp": 1585810276997,
     "user": {
      "displayName": "Алексей Кузьмин",
      "photoUrl": "",
      "userId": "13824739836143424630"
     },
     "user_tz": -180
    },
    "id": "6dZOGjd5M9uE",
    "outputId": "823ec161-19b3-468c-8630-93de6e8aab47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 380911 sentence pairs\n",
      "Trimmed to 380366 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "rus 52635\n",
      "eng 15753\n",
      "['меня поражает его эрудиция .', 'his extensive knowledge surprises me .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\" Applies attention mechanism on the `context` using the `query`.\n",
    "\n",
    "    **Thank you** to IBM for their initial implementation of :class:`Attention`. Here is\n",
    "    their `License\n",
    "    <https://github.com/IBM/pytorch-seq2seq/blob/master/LICENSE>`__.\n",
    "\n",
    "    Args:\n",
    "        dimensions (int): Dimensionality of the query and context.\n",
    "        attention_type (str, optional): How to compute the attention score:\n",
    "\n",
    "            * dot: :math:`score(H_j,q) = H_j^T q`\n",
    "            * general: :math:`score(H_j, q) = H_j^T W_a q`\n",
    "\n",
    "    Example:\n",
    "\n",
    "         >>> attention = Attention(256)\n",
    "         >>> query = torch.randn(5, 1, 256)\n",
    "         >>> context = torch.randn(5, 5, 256)\n",
    "         >>> output, weights = attention(query, context)\n",
    "         >>> output.size()\n",
    "         torch.Size([5, 1, 256])\n",
    "         >>> weights.size()\n",
    "         torch.Size([5, 1, 5])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dimensions, attention_type='general'):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        if attention_type not in ['dot', 'general']:\n",
    "            raise ValueError('Invalid attention type selected.')\n",
    "\n",
    "        self.attention_type = attention_type\n",
    "        if self.attention_type == 'general':\n",
    "            self.linear_in = nn.Linear(dimensions, dimensions, bias=False)\n",
    "\n",
    "        self.linear_out = nn.Linear(dimensions * 2, dimensions, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, query, context):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query (:class:`torch.FloatTensor` [batch size, output length, dimensions]): Sequence of\n",
    "                queries to query the context.\n",
    "            context (:class:`torch.FloatTensor` [batch size, query length, dimensions]): Data\n",
    "                overwhich to apply the attention mechanism.\n",
    "\n",
    "        Returns:\n",
    "            :class:`tuple` with `output` and `weights`:\n",
    "            * **output** (:class:`torch.LongTensor` [batch size, output length, dimensions]):\n",
    "              Tensor containing the attended features.\n",
    "            * **weights** (:class:`torch.FloatTensor` [batch size, output length, query length]):\n",
    "              Tensor containing attention weights.\n",
    "        \"\"\"\n",
    "        batch_size, output_len, dimensions = query.size()\n",
    "        query_len = context.size(1)\n",
    "\n",
    "        if self.attention_type == \"general\":\n",
    "            query = query.reshape(batch_size * output_len, dimensions)\n",
    "            query = self.linear_in(query)\n",
    "            query = query.reshape(batch_size, output_len, dimensions)\n",
    "\n",
    "        # TODO: Include mask on PADDING_INDEX?\n",
    "\n",
    "        # (batch_size, output_len, dimensions) * (batch_size, query_len, dimensions) ->\n",
    "        # (batch_size, output_len, query_len)\n",
    "        attention_scores = torch.bmm(query, context.transpose(1, 2).contiguous())\n",
    "\n",
    "        # Compute weights across every context sequence\n",
    "        attention_scores = attention_scores.view(batch_size * output_len, query_len)\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "        attention_weights = attention_weights.view(batch_size, output_len, query_len)\n",
    "\n",
    "        # (batch_size, output_len, query_len) * (batch_size, query_len, dimensions) ->\n",
    "        # (batch_size, output_len, dimensions)\n",
    "        mix = torch.bmm(attention_weights, context)\n",
    "\n",
    "        # concat -> (batch_size * output_len, 2*dimensions)\n",
    "        combined = torch.cat((mix, query), dim=2)\n",
    "        combined = combined.view(batch_size * output_len, 2 * dimensions)\n",
    "\n",
    "        # Apply linear_out on every 2nd dimension of concat\n",
    "        # output -> (batch_size, output_len, dimensions)\n",
    "        output = self.linear_out(combined).view(batch_size, output_len, dimensions)\n",
    "        output = self.tanh(output)\n",
    "\n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 256])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Проверим работоспособность класса attention\n",
    "\n",
    "attention = Attention(256, attention_type = 'dot')\n",
    "query = torch.randn(5, 1, 256)\n",
    "context = torch.randn(5, 5, 256)\n",
    "output, weights = attention(query, context)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(a, b):\n",
    "    \"\"\"Compute the dot product between pairs of vectors in 3D Variables.\n",
    "    \n",
    "        Args\n",
    "        ----\n",
    "        a: Variable of size (B, M, D)\n",
    "        b: Variable of size (B, N, D)\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        c: Variable of size (B, M, N)\n",
    "            c[i,j,k] = dot(a[i,j], b[i,k])\n",
    "    \"\"\"\n",
    "    return a.bmm(b.transpose(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgtWqznCM9uH"
   },
   "source": [
    "The Encoder\n",
    "-----------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9vm9QBWM9uI"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwLTlgSyM9uK"
   },
   "source": [
    "The Decoder\n",
    "-----------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFbuUL1LM9uL"
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "    \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN_matmull(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN_matmull, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.attention = Attention(256, attention_type = 'dot')\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        #attn_weights = F.softmax(\n",
    "        #    self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        #print(attn_weights.unsqueeze(0).size())\n",
    "        #print(encoder_outputs.unsqueeze(0).size())\n",
    "        #attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "        #                         encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        #output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        #output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        #output = F.relu(output)\n",
    "        \n",
    "        \n",
    "        ### перепишем функцию аттеншн просто на в слое аттеншн\n",
    "        query =  hidden[0].unsqueeze(0)\n",
    "        context = encoder_outputs.unsqueeze(0)\n",
    "        output, attn_weights = self.attention(query, context)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6gGPtXFM9uQ"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Fn8VDv8M9uS"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKsdwPmSM9uU"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_z_k5IiM9uX"
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, encoder_optimizer, decoder_optimizer):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JXG-RzCM9uZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Bxf45h6M9ud"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qUmQIGwM9uf"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1239015,
     "status": "ok",
     "timestamp": 1585811635577,
     "user": {
      "displayName": "Алексей Кузьмин",
      "photoUrl": "",
      "userId": "13824739836143424630"
     },
     "user_tz": -180
    },
    "id": "s_56t10oM9uh",
    "outputId": "e18f1e4f-453d-4266-c2a3-110f94d20308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 12s (- 11m 2s) (5000 16%) 4.4445\n",
      "4m 26s (- 8m 52s) (10000 33%) 3.9246\n",
      "6m 40s (- 6m 40s) (15000 50%) 3.6463\n",
      "8m 55s (- 4m 27s) (20000 66%) 3.4229\n",
      "11m 10s (- 2m 14s) (25000 83%) 3.2884\n",
      "13m 25s (- 0m 0s) (30000 100%) 3.1604\n"
     ]
    }
   ],
   "source": [
    "#### Запустим обучение с MLP аттеншн\n",
    "\n",
    "\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "leaning_rate = 0.01\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 30000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 17s (- 11m 26s) (5000 16%) 3.0790\n",
      "4m 33s (- 9m 6s) (10000 33%) 3.0279\n",
      "6m 49s (- 6m 49s) (15000 50%) 2.9254\n",
      "9m 4s (- 4m 32s) (20000 66%) 2.9031\n",
      "11m 20s (- 2m 16s) (25000 83%) 2.8633\n",
      "13m 36s (- 0m 0s) (30000 100%) 2.8234\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.SGD(encoder1.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(attn_decoder1.parameters(), lr=learning_rate)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 30000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 18s (- 11m 32s) (5000 16%) 2.7424\n",
      "4m 33s (- 9m 7s) (10000 33%) 2.7487\n",
      "6m 48s (- 6m 48s) (15000 50%) 2.7038\n",
      "9m 5s (- 4m 32s) (20000 66%) 2.6782\n",
      "11m 21s (- 2m 16s) (25000 83%) 2.6560\n",
      "13m 38s (- 0m 0s) (30000 100%) 2.6211\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder1.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(attn_decoder1.parameters(), lr=learning_rate)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 30000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 17s (- 11m 27s) (5000 16%) 2.5994\n",
      "4m 33s (- 9m 7s) (10000 33%) 2.6118\n",
      "6m 49s (- 6m 49s) (15000 50%) 2.5614\n",
      "9m 5s (- 4m 32s) (20000 66%) 2.5722\n",
      "11m 21s (- 2m 16s) (25000 83%) 2.5398\n",
      "13m 37s (- 0m 0s) (30000 100%) 2.4959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.AdamW(encoder1.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.AdamW(attn_decoder1.parameters(), lr=learning_rate)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 30000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 4s (- 10m 22s) (5000 16%) 4.7193\n",
      "4m 8s (- 8m 17s) (10000 33%) 4.1818\n",
      "6m 14s (- 6m 14s) (15000 50%) 3.9400\n",
      "8m 19s (- 4m 9s) (20000 66%) 3.7109\n",
      "10m 23s (- 2m 4s) (25000 83%) 3.5642\n",
      "12m 28s (- 0m 0s) (30000 100%) 3.4220\n"
     ]
    }
   ],
   "source": [
    "#### Запустим обучение с dot аттеншн\n",
    "\n",
    "hidden_size = 256\n",
    "encoder2 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder2 = AttnDecoderRNN_matmull(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "learning_rate = 0.01\n",
    "encoder_optimizer = optim.SGD(encoder2.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(attn_decoder2.parameters(), lr=learning_rate)\n",
    "\n",
    "trainIters(encoder2, attn_decoder2, 30000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 7s (- 10m 37s) (5000 16%) 3.4163\n",
      "4m 12s (- 8m 25s) (10000 33%) 3.3049\n",
      "6m 17s (- 6m 17s) (15000 50%) 3.2772\n",
      "8m 22s (- 4m 11s) (20000 66%) 3.2353\n",
      "10m 27s (- 2m 5s) (25000 83%) 3.2156\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.SGD(encoder2.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(attn_decoder2.parameters(), lr=learning_rate)\n",
    "\n",
    "trainIters(encoder2, attn_decoder2, 30000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 9s (- 10m 46s) (5000 16%) 3.0575\n",
      "4m 14s (- 8m 28s) (10000 33%) 3.0437\n",
      "6m 19s (- 6m 19s) (15000 50%) 3.0616\n",
      "8m 25s (- 4m 12s) (20000 66%) 3.0163\n",
      "10m 30s (- 2m 6s) (25000 83%) 3.0397\n",
      "12m 34s (- 0m 0s) (30000 100%) 3.0586\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder2.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(attn_decoder2.parameters(), lr=learning_rate)\n",
    "\n",
    "trainIters(encoder2, attn_decoder2, 30000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 741
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1228237,
     "status": "ok",
     "timestamp": 1585811635578,
     "user": {
      "displayName": "Алексей Кузьмин",
      "photoUrl": "",
      "userId": "13824739836143424630"
     },
     "user_tz": -180
    },
    "id": "xEoEylSyM9uj",
    "outputId": "94ddd55b-0f6c-4af5-fb58-f5d4422ae1d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> научите меня водить машину пожалуиста .\n",
      "= please teach me how to drive .\n",
      "< please drive me in the car . <EOS>\n",
      "\n",
      "> все таки страшновато .\n",
      "= it is still a little scary .\n",
      "< everybody is so stupid . <EOS>\n",
      "\n",
      "> никто не сказал мне что она потерпела неудачу .\n",
      "= no one told me that she had failed .\n",
      "< no one told me me she was was . <EOS>\n",
      "\n",
      "> это было довольно просто .\n",
      "= it was quite simple .\n",
      "< it was a bad . <EOS>\n",
      "\n",
      "> вы деиствительно так сказали ?\n",
      "= did you really say that ?\n",
      "< are you really what to say ? <EOS>\n",
      "\n",
      "> ты видел как я танцую ?\n",
      "= have you seen me dance ?\n",
      "< did you saw the man ? ? <EOS>\n",
      "\n",
      "> он ругается всякии раз как разозлится .\n",
      "= he uses foul language whenever he gets angry .\n",
      "< he is as as as as . <EOS>\n",
      "\n",
      "> я не люблю смотреть фильмы .\n",
      "= i don t like movies .\n",
      "< i don t like to books . <EOS>\n",
      "\n",
      "> большинство людеи живет в городскои местности .\n",
      "= most people live in urban areas .\n",
      "< most people in in people in in the <EOS>\n",
      "\n",
      "> может быть вы уже перестанете меня об этом спрашивать ?\n",
      "= i wish you d stop asking me that .\n",
      "< how can you tell me this this ? ? <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> том сказал что не хочет чтобы я рассказывал мэри что случилось .\n",
      "= tom said he didn t want me to tell mary what happened .\n",
      "< tom said he was t was was was was . . . . . . . . . . .\n",
      "\n",
      "> она окинула меня многозначительным взглядом .\n",
      "= she gave me a meaningful look .\n",
      "< she is a a . . . . . <EOS>\n",
      "\n",
      "> прости что вчера на вас наорал .\n",
      "= i m sorry i yelled at you yesterday .\n",
      "< i m sorry you was last you . . . . . . . . . . . . .\n",
      "\n",
      "> ты безнадежна .\n",
      "= you re desperate .\n",
      "< you re . . <EOS>\n",
      "\n",
      "> мне весело .\n",
      "= i m having fun .\n",
      "< i m me . . . <EOS>\n",
      "\n",
      "> я свободна этим вечером .\n",
      "= i m free this evening .\n",
      "< i m that this . . . <EOS>\n",
      "\n",
      "> я бы помог тебе если бы ты захотел .\n",
      "= i d help you if you want me to .\n",
      "< i d d if if if if . . . . . . . . . . . . .\n",
      "\n",
      "> я не знаю с кем вы хотите встретиться .\n",
      "= i don t know who you want to meet .\n",
      "< i don t know you you to to the . . . . . . . <EOS>\n",
      "\n",
      "> я знаю что это не тот ответ которыи вы хотели услышать .\n",
      "= i know that wasn t the answer you wanted .\n",
      "< i know that you not not not not not not not . . . . . . . . .\n",
      "\n",
      "> том простил мэри за то что она потеряла все его деньги .\n",
      "= tom forgave mary for losing all his money .\n",
      "< tom is mary that her for for . . . . . . . . . . . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder2, attn_decoder2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На текстах видно что dot attention работает хуже чем MLP attention\n",
    "\n",
    "#### Визуализируем attention для двух разных механизмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1116,
     "status": "ok",
     "timestamp": 1585811694987,
     "user": {
      "displayName": "Алексей Кузьмин",
      "photoUrl": "",
      "userId": "13824739836143424630"
     },
     "user_tz": -180
    },
    "id": "vzc3k6D0qn9W",
    "outputId": "26983998-4520-47ca-e925-cb5b0d2bc286"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 822.857x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"научите меня водить машину пожалуиста .\")\n",
    "plt.matshow(attentions.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder2, attn_decoder2, \"научите меня водить машину пожалуиста .\")\n",
    "plt.matshow(attentions.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1440,
     "status": "ok",
     "timestamp": 1585811699817,
     "user": {
      "displayName": "Алексей Кузьмин",
      "photoUrl": "",
      "userId": "13824739836143424630"
     },
     "user_tz": -180
    },
    "id": "6fqVhe4yqpeY",
    "outputId": "e2297caa-8592-493a-cf04-f4ee406f58f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = научите меня водить машину пожалуиста .\n",
      "output = please drive me in the car . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention1(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention1(\"научите меня водить машину пожалуиста .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcoNw3Tzqs8q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = научите меня водить машину пожалуиста .\n",
      "output = i me me i i . . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluateAndShowAttention2(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder2, attn_decoder2, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention2(\"научите меня водить машину пожалуиста .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Лекция 9.ipynb",
   "provenance": [
    {
     "file_id": "1OYzlqXRnnAbkDwokKbOYuvXCfxbZ6lnf",
     "timestamp": 1585810119247
    },
    {
     "file_id": "https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/seq2seq_translation_tutorial.ipynb",
     "timestamp": 1584645023061
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
