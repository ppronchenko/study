{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "\n",
    "from torch import nn\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotation = pd.read_csv('TsignRecgTrain4170Annotation.txt', sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_annotation = train_annotation.sort_values(by=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>42</td>\n",
       "      <td>001_0013.png</td>\n",
       "      <td>146</td>\n",
       "      <td>139</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>127</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index             0    1    2   3   4    5    6  7   8\n",
       "131     42  001_0013.png  146  139  30  24  127  118  1 NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_annotation.loc[train_annotation[0] == '001_0013.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = train_annotation[7]\n",
    "tars = torch.Tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = tv.transforms.Compose([tv.transforms.Resize([64, 64]), \n",
    "                              tv.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.ImageFolder('/home/plpronchenko/study_data/DL_4_HW/Train/', transform= augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#подставим метки из файла с описанием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.targets = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4170,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_dict = {}\n",
    "for k, v in zip(train_annotation.loc[:, [0]].values, train_annotation.loc[:, [7]].values):\n",
    "     targets_dict[k[0]] = v[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels = []\n",
    "\n",
    "for i in range(len(train_dataset.samples)-1):\n",
    "    img_file = train_dataset.samples[i][0].split('/')[-1]\n",
    "    correct_labels.append((train_dataset.samples[i][0], targets_dict[img_file]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/plpronchenko/study_data/DL_4_HW/Train/0/001_0013.png', 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_labels[131]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.samples = correct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим датасет с тестовыми данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annotation = pd.read_csv('TsignRecgTest1994Annotation.txt', sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_annotation = test_annotation.sort_values(by=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tv.datasets.ImageFolder('/home/plpronchenko/study_data/DL_4_HW/Test/', transform = augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_dict = {}\n",
    "for k, v in zip(test_annotation.loc[:, [0]].values, test_annotation.loc[:, [7]].values):\n",
    "     targets_dict[k[0]] = v[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels = []\n",
    "\n",
    "for i in range(len(test_dataset.samples)-1):\n",
    "    img_file = test_dataset.samples[i][0].split('/')[-1]\n",
    "    correct_labels.append((test_dataset.samples[i][0], targets_dict[img_file]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.samples = correct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = test_annotation[7]\n",
    "test_dataset.targets = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>560</td>\n",
       "      <td>028_0010_j.png</td>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index               0   1   2   3  4   5   6   7   8\n",
       "1111    560  028_0010_j.png  87  70  16  7  60  54  28 NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_annotation.loc[test_annotation[0] == '028_0010_j.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.targets[1111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/plpronchenko/study_data/DL_4_HW/Test/0/028_0010_j.png', 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.samples[1111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28    446\n",
       "54    324\n",
       "3     260\n",
       "5     194\n",
       "55    162\n",
       "35    156\n",
       "7     152\n",
       "30    150\n",
       "16    142\n",
       "11    138\n",
       "17    130\n",
       "14    128\n",
       "26    126\n",
       "0     118\n",
       "56    110\n",
       "24    100\n",
       "4      98\n",
       "12     96\n",
       "43     82\n",
       "2      80\n",
       "6      78\n",
       "10     70\n",
       "37     58\n",
       "50     56\n",
       "29     44\n",
       "49     42\n",
       "31     42\n",
       "1      40\n",
       "36     40\n",
       "52     36\n",
       "13     36\n",
       "39     34\n",
       "40     32\n",
       "42     32\n",
       "38     30\n",
       "44     30\n",
       "27     28\n",
       "34     26\n",
       "45     24\n",
       "15     22\n",
       "41     18\n",
       "22     18\n",
       "46     18\n",
       "20     18\n",
       "23     14\n",
       "32     14\n",
       "21     12\n",
       "47     12\n",
       "48     10\n",
       "8       8\n",
       "51      8\n",
       "18      8\n",
       "57      6\n",
       "19      4\n",
       "33      4\n",
       "25      2\n",
       "9       2\n",
       "53      2\n",
       "Name: 7, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.targets.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54    176\n",
       "26    134\n",
       "11    130\n",
       "43    116\n",
       "13     92\n",
       "3      84\n",
       "17     84\n",
       "16     76\n",
       "28     68\n",
       "10     60\n",
       "2      60\n",
       "55     58\n",
       "4      58\n",
       "5      50\n",
       "7      50\n",
       "35     46\n",
       "49     42\n",
       "38     40\n",
       "56     40\n",
       "15     36\n",
       "30     34\n",
       "39     30\n",
       "6      30\n",
       "52     30\n",
       "29     26\n",
       "37     26\n",
       "24     26\n",
       "27     24\n",
       "44     24\n",
       "12     22\n",
       "50     20\n",
       "31     18\n",
       "42     18\n",
       "8      14\n",
       "0      14\n",
       "46     14\n",
       "21     12\n",
       "36     12\n",
       "1      12\n",
       "14     12\n",
       "23     10\n",
       "47     10\n",
       "41      8\n",
       "40      8\n",
       "34      8\n",
       "22      8\n",
       "48      6\n",
       "51      4\n",
       "57      4\n",
       "20      2\n",
       "45      2\n",
       "32      2\n",
       "25      2\n",
       "53      2\n",
       "Name: 7, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.targets.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наблюдаем дисбаланс классов как в трейне так и в тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  постороим LeNet \n",
    "# - выход на 58 классов знаков\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 6, kernel_size=5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(6, 12, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.BatchNorm1d(2352),\n",
    "    nn.Linear(2352, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 58)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 29607.9067, train acc 0.077, test acc 0.023, time 9.8 sec\n",
      "epoch 2, loss 3.6693, train acc 0.090, test acc 0.034, time 9.4 sec\n",
      "epoch 3, loss 3.6558, train acc 0.090, test acc 0.034, time 9.3 sec\n",
      "epoch 4, loss 3.6594, train acc 0.083, test acc 0.034, time 9.3 sec\n",
      "epoch 5, loss 3.6695, train acc 0.094, test acc 0.034, time 9.4 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.05, 5\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=lr, momentum = 0.9)\n",
    "train(model, train_iter, test_iter, trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.001, 20\n",
    "trainer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "train(model, train_iter, test_iter, trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# максимум acc на тесте - 0.034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = tv.transforms.Compose([tv.transforms.Resize([224, 224]), \n",
    "                              tv.transforms.ToTensor(),\n",
    "                              tv.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.ImageFolder('/home/plpronchenko/study_data/DL_4_HW/Train/', transform= augs)\n",
    "correct_labels = []\n",
    "\n",
    "targets_dict = {}\n",
    "for k, v in zip(train_annotation.loc[:, [0]].values, train_annotation.loc[:, [7]].values):\n",
    "     targets_dict[k[0]] = v[0] \n",
    "\n",
    "correct_labels = []\n",
    "\n",
    "for i in range(len(train_dataset.samples)-1):\n",
    "    img_file = train_dataset.samples[i][0].split('/')[-1]\n",
    "    correct_labels.append((train_dataset.samples[i][0], targets_dict[img_file]))\n",
    "\n",
    "train_dataset.samples = correct_labels\n",
    "\n",
    "targets = train_annotation[7]\n",
    "train_dataset.targets = targets\n",
    "\n",
    "\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tv.datasets.ImageFolder('/home/plpronchenko/study_data/DL_4_HW/Test/', transform = augs)\n",
    "\n",
    "targets_dict = {}\n",
    "for k, v in zip(test_annotation.loc[:, [0]].values, test_annotation.loc[:, [7]].values):\n",
    "     targets_dict[k[0]] = v[0] \n",
    "        \n",
    "correct_labels = []\n",
    "\n",
    "for i in range(len(test_dataset.samples)-1):\n",
    "    img_file = test_dataset.samples[i][0].split('/')[-1]\n",
    "    correct_labels.append((test_dataset.samples[i][0], targets_dict[img_file]))\n",
    "\n",
    "\n",
    "test_dataset.samples = correct_labels\n",
    "\n",
    "targets = test_annotation[7]\n",
    "test_dataset.targets = targets\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = tv.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.fc = nn.Linear(in_features=2048, out_features=58, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "resnet50 = resnet50.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 4.1748, train acc 0.130, test acc 0.095, time 43.1 sec\n",
      "epoch 2, loss 3.0294, train acc 0.223, test acc 0.152, time 42.9 sec\n",
      "epoch 3, loss 2.4462, train acc 0.325, test acc 0.209, time 45.9 sec\n",
      "epoch 4, loss 2.0672, train acc 0.396, test acc 0.236, time 54.1 sec\n",
      "epoch 5, loss 1.7713, train acc 0.466, test acc 0.265, time 59.8 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 5\n",
    "trainer = torch.optim.SGD(resnet50.parameters(), lr=lr)\n",
    "train(resnet50, train_iter, test_iter, trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.2714, train acc 0.611, test acc 0.286, time 60.8 sec\n",
      "epoch 2, loss 1.1081, train acc 0.650, test acc 0.295, time 63.7 sec\n",
      "epoch 3, loss 0.9735, train acc 0.695, test acc 0.325, time 62.9 sec\n",
      "epoch 4, loss 0.8324, train acc 0.738, test acc 0.298, time 63.4 sec\n",
      "epoch 5, loss 0.7469, train acc 0.765, test acc 0.346, time 64.2 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "trainer = torch.optim.SGD(resnet50.parameters(), lr=lr, momentum = 0.7)\n",
    "train(resnet50, train_iter, test_iter, trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.5228, train acc 0.846, test acc 0.380, time 66.3 sec\n",
      "epoch 2, loss 0.4528, train acc 0.862, test acc 0.391, time 63.2 sec\n",
      "epoch 3, loss 0.4273, train acc 0.870, test acc 0.393, time 63.6 sec\n",
      "epoch 4, loss 0.3844, train acc 0.883, test acc 0.379, time 66.4 sec\n",
      "epoch 5, loss 0.3687, train acc 0.889, test acc 0.379, time 65.4 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.0001, 5\n",
    "trainer = torch.optim.SGD(resnet50.parameters(), lr=lr, momentum = 0.7)\n",
    "train(resnet50, train_iter, test_iter, trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# На тесте качество 0.393 - пока максимум который удалось выучить "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = resnet50.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = []\n",
    "y_true = []\n",
    "for X, y in test_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        pred = resnet50(X)\n",
    "        predict_test.append(pred)\n",
    "        y_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in predict_test:\n",
    "    for j in i:\n",
    "        z = j.cpu().detach().numpy()\n",
    "        for h in range(len(z)):\n",
    "            if z[h] == np.max(z):\n",
    "                  preds.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
