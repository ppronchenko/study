{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T21:09:22.893628Z",
     "start_time": "2019-11-11T21:09:22.601085Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import time\n",
    "BATCH_SIZE=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('./fashion', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('./fashion', train=False, transform=tv.transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T21:23:40.230893Z",
     "start_time": "2019-11-11T21:23:40.189035Z"
    }
   },
   "outputs": [],
   "source": [
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T21:23:40.795687Z",
     "start_time": "2019-11-11T21:23:40.672226Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4c43c35208>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[3][0].numpy().reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постороим модель - сделаем ее глубже и добавим слои BatchNorm и DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T21:23:41.010511Z",
     "start_time": "2019-11-11T21:23:41.003495Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.BatchNorm1d(784),\n",
    "    torch.nn.Linear(784, 3136),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(3136),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(3136, 1568),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(1568),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(1568, 392),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(392),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(392, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-11T21:23:41.448Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, train, test, trainer, dev):\n",
    "    for ep in range(num_epochs):\n",
    "        train_iters, train_passed  = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "    \n",
    "        for X, y in train:\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "    \n",
    "        test_iters, test_passed  = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        for X, y in test:\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "        \n",
    "        print(\"ep: {}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "            ep, train_loss / train_iters, train_acc / train_passed,\n",
    "            test_loss / test_iters, test_acc / test_passed)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, train_loss: 209.9827484842074, train_acc: 0.8554666666666667, test_loss: 210.3841896057129, test_acc: 0.8496\n",
      "ep: 1, train_loss: 179.0713008945271, train_acc: 0.8710166666666667, test_loss: 211.09325218200684, test_acc: 0.8542\n",
      "ep: 2, train_loss: 165.96007857888432, train_acc: 0.8824166666666666, test_loss: 211.74167022705078, test_acc: 0.8503\n",
      "ep: 3, train_loss: 158.96354888657393, train_acc: 0.88525, test_loss: 193.81148262023925, test_acc: 0.8635\n",
      "ep: 4, train_loss: 154.1160336995529, train_acc: 0.8888, test_loss: 208.4253402709961, test_acc: 0.8563\n",
      "ep: 5, train_loss: 150.6066830521923, train_acc: 0.8921166666666667, test_loss: 197.51052780151366, test_acc: 0.8583\n",
      "ep: 6, train_loss: 150.64541832875398, train_acc: 0.8911666666666667, test_loss: 226.97397537231444, test_acc: 0.8483\n",
      "ep: 7, train_loss: 157.0436385203216, train_acc: 0.8867333333333334, test_loss: 216.97005958557128, test_acc: 0.8556\n",
      "ep: 8, train_loss: 144.3430404663086, train_acc: 0.8956333333333333, test_loss: 202.41471481323242, test_acc: 0.8657\n",
      "ep: 9, train_loss: 138.76537268040545, train_acc: 0.9006333333333333, test_loss: 195.72989730834962, test_acc: 0.8685\n"
     ]
    }
   ],
   "source": [
    "#Учим в несколько этапов, уменьшая lr\n",
    "loss = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "trainer = torch.optim.AdamW(model.parameters(), lr=0.05)\n",
    "num_epochs = 10\n",
    "train_model(model, num_epochs, train, test, trainer, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, train_loss: 108.86684000694146, train_acc: 0.9195, test_loss: 168.03835487365723, test_acc: 0.8885\n",
      "ep: 1, train_loss: 97.5175813577943, train_acc: 0.9276, test_loss: 169.81521186828613, test_acc: 0.8893\n",
      "ep: 2, train_loss: 90.235651210203, train_acc: 0.9332166666666667, test_loss: 169.68197021484374, test_acc: 0.8925\n",
      "ep: 3, train_loss: 86.3177361084243, train_acc: 0.9351166666666667, test_loss: 175.81413688659669, test_acc: 0.8889\n",
      "ep: 4, train_loss: 81.96019976017838, train_acc: 0.9389333333333333, test_loss: 181.1027629852295, test_acc: 0.889\n",
      "ep: 5, train_loss: 77.24450407998036, train_acc: 0.9423833333333334, test_loss: 190.1218704223633, test_acc: 0.8893\n",
      "ep: 6, train_loss: 72.90944213382268, train_acc: 0.9458333333333333, test_loss: 189.07061996459962, test_acc: 0.891\n",
      "ep: 7, train_loss: 69.80571743593377, train_acc: 0.9482833333333334, test_loss: 196.55829467773438, test_acc: 0.8896\n",
      "ep: 8, train_loss: 65.21881636118485, train_acc: 0.9517166666666667, test_loss: 200.96943550109864, test_acc: 0.8921\n",
      "ep: 9, train_loss: 61.60529682595851, train_acc: 0.9544833333333334, test_loss: 210.75151519775392, test_acc: 0.8922\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "trainer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "num_epochs = 10\n",
    "train_model(model, num_epochs, train, test, trainer, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, train_loss: 54.082676475330935, train_acc: 0.9595833333333333, test_loss: 206.62062377929686, test_acc: 0.8945\n",
      "ep: 1, train_loss: 53.381392903247125, train_acc: 0.9600833333333333, test_loss: 202.67377586364745, test_acc: 0.8939\n",
      "ep: 2, train_loss: 51.82344270560701, train_acc: 0.9616333333333333, test_loss: 215.9363597869873, test_acc: 0.8932\n",
      "ep: 3, train_loss: 50.64857908022606, train_acc: 0.9626, test_loss: 208.23628349304198, test_acc: 0.8939\n",
      "ep: 4, train_loss: 50.86651248446966, train_acc: 0.9632333333333334, test_loss: 208.80577812194824, test_acc: 0.8918\n",
      "ep: 5, train_loss: 50.43816340171685, train_acc: 0.9621166666666666, test_loss: 210.73864250183107, test_acc: 0.8951\n",
      "ep: 6, train_loss: 49.80931458634845, train_acc: 0.9632333333333334, test_loss: 211.79404258728027, test_acc: 0.8926\n",
      "ep: 7, train_loss: 49.64147871631687, train_acc: 0.9635666666666667, test_loss: 212.8428783416748, test_acc: 0.8928\n",
      "ep: 8, train_loss: 48.97796222719096, train_acc: 0.96415, test_loss: 213.18702278137206, test_acc: 0.8953\n",
      "ep: 9, train_loss: 48.22263804936813, train_acc: 0.9641666666666666, test_loss: 215.310396194458, test_acc: 0.897\n"
     ]
    }
   ],
   "source": [
    "# Поменяем оптимизатор на AdamW для стабилизации тренировки\n",
    "loss = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "trainer = torch.optim.AdamW(model.parameters(), lr=0.0002)\n",
    "num_epochs = 10\n",
    "train_model(model, num_epochs, train, test, trainer, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, train_loss: 48.13766174801325, train_acc: 0.96435, test_loss: 219.667085647583, test_acc: 0.8942\n",
      "ep: 1, train_loss: 48.241349680949064, train_acc: 0.96405, test_loss: 215.93485107421876, test_acc: 0.8947\n",
      "ep: 2, train_loss: 47.27962952145075, train_acc: 0.9647166666666667, test_loss: 218.63507270812988, test_acc: 0.8955\n",
      "ep: 3, train_loss: 47.621523598493155, train_acc: 0.9651166666666666, test_loss: 219.56253776550292, test_acc: 0.8934\n",
      "ep: 4, train_loss: 46.47283081685082, train_acc: 0.9652, test_loss: 218.2619472503662, test_acc: 0.8933\n",
      "ep: 5, train_loss: 47.813264871047714, train_acc: 0.9649166666666666, test_loss: 220.659814453125, test_acc: 0.8941\n",
      "ep: 6, train_loss: 46.86701483645682, train_acc: 0.9645833333333333, test_loss: 220.82618408203126, test_acc: 0.8952\n",
      "ep: 7, train_loss: 47.21398870823747, train_acc: 0.9654666666666667, test_loss: 214.28051147460937, test_acc: 0.8941\n",
      "ep: 8, train_loss: 46.34979126817089, train_acc: 0.96555, test_loss: 221.48496055603027, test_acc: 0.8931\n",
      "ep: 9, train_loss: 47.03067624366889, train_acc: 0.9654666666666667, test_loss: 223.37666854858398, test_acc: 0.8925\n",
      "ep: 10, train_loss: 46.604303695387756, train_acc: 0.9659, test_loss: 219.16061134338378, test_acc: 0.8947\n",
      "ep: 11, train_loss: 45.87570221949432, train_acc: 0.9659166666666666, test_loss: 216.6927635192871, test_acc: 0.8945\n",
      "ep: 12, train_loss: 45.78792587377257, train_acc: 0.9661333333333333, test_loss: 224.94415550231935, test_acc: 0.8929\n",
      "ep: 13, train_loss: 46.02680255598941, train_acc: 0.9662333333333334, test_loss: 226.6960594177246, test_acc: 0.8929\n",
      "ep: 14, train_loss: 46.08258397700423, train_acc: 0.9654, test_loss: 222.19013366699218, test_acc: 0.8933\n",
      "ep: 15, train_loss: 46.34654760764817, train_acc: 0.96575, test_loss: 217.19414710998535, test_acc: 0.8939\n",
      "ep: 16, train_loss: 45.90238159793918, train_acc: 0.9664, test_loss: 223.76943550109863, test_acc: 0.8943\n",
      "ep: 17, train_loss: 45.407624345714765, train_acc: 0.9668833333333333, test_loss: 224.882413482666, test_acc: 0.8929\n",
      "ep: 18, train_loss: 45.78500439757008, train_acc: 0.9657333333333333, test_loss: 222.97013511657715, test_acc: 0.8937\n",
      "ep: 19, train_loss: 44.962654287532224, train_acc: 0.9668666666666667, test_loss: 224.1674777984619, test_acc: 0.8922\n",
      "ep: 20, train_loss: 45.58693133370351, train_acc: 0.9667666666666667, test_loss: 221.3486255645752, test_acc: 0.8941\n",
      "ep: 21, train_loss: 44.93554292694997, train_acc: 0.9665166666666667, test_loss: 226.17705230712892, test_acc: 0.8925\n",
      "ep: 22, train_loss: 44.58795133687682, train_acc: 0.9675, test_loss: 218.62188873291015, test_acc: 0.8984\n",
      "ep: 23, train_loss: 44.76585888458511, train_acc: 0.9669, test_loss: 231.84098777770996, test_acc: 0.8944\n",
      "ep: 24, train_loss: 44.54528594421128, train_acc: 0.9668166666666667, test_loss: 226.59157943725586, test_acc: 0.8932\n",
      "ep: 25, train_loss: 44.04437641774194, train_acc: 0.9679333333333333, test_loss: 226.9639041900635, test_acc: 0.8935\n",
      "ep: 26, train_loss: 44.72830031281811, train_acc: 0.9664833333333334, test_loss: 224.75384025573732, test_acc: 0.8942\n",
      "ep: 27, train_loss: 44.398972276913916, train_acc: 0.9665, test_loss: 224.72194747924806, test_acc: 0.8932\n",
      "ep: 28, train_loss: 44.797093427787395, train_acc: 0.9673, test_loss: 229.55585556030275, test_acc: 0.8937\n",
      "ep: 29, train_loss: 43.69776275198338, train_acc: 0.9680666666666666, test_loss: 227.48650970458985, test_acc: 0.8975\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "trainer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "num_epochs = 30\n",
    "train_model(model, num_epochs, train, test, trainer, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#максимум на тесте - 0.8984"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
