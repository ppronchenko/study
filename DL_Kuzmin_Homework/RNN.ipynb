{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T09:51:06.410976Z",
     "start_time": "2019-11-21T09:51:05.943748Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T09:53:46.911106Z",
     "start_time": "2019-11-21T09:53:46.840248Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T09:53:49.823811Z",
     "start_time": "2019-11-21T09:53:49.793482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>number</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>timestamp_in_ms</th>\n",
       "      <th>speaking_line</th>\n",
       "      <th>character_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>raw_location_text</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10368</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>Lisa Simpson: Maggie, look. What's that?</td>\n",
       "      <td>235000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>Maggie, look. What's that?</td>\n",
       "      <td>maggie look whats that</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10369</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>Lisa Simpson: Lee-mur. Lee-mur.</td>\n",
       "      <td>237000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>Lee-mur. Lee-mur.</td>\n",
       "      <td>lee-mur lee-mur</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10370</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>Lisa Simpson: Zee-boo. Zee-boo.</td>\n",
       "      <td>239000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>Zee-boo. Zee-boo.</td>\n",
       "      <td>zee-boo zee-boo</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10372</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>Lisa Simpson: I'm trying to teach Maggie that ...</td>\n",
       "      <td>245000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>I'm trying to teach Maggie that nature doesn't...</td>\n",
       "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10374</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>Lisa Simpson: It's like an ox, only it has a h...</td>\n",
       "      <td>254000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>It's like an ox, only it has a hump and a dewl...</td>\n",
       "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id  episode_id  number  \\\n",
       "0           0  10368          35      29   \n",
       "1           1  10369          35      30   \n",
       "2           2  10370          35      31   \n",
       "3           3  10372          35      33   \n",
       "4           4  10374          35      35   \n",
       "\n",
       "                                            raw_text  timestamp_in_ms  \\\n",
       "0           Lisa Simpson: Maggie, look. What's that?           235000   \n",
       "1                    Lisa Simpson: Lee-mur. Lee-mur.           237000   \n",
       "2                    Lisa Simpson: Zee-boo. Zee-boo.           239000   \n",
       "3  Lisa Simpson: I'm trying to teach Maggie that ...           245000   \n",
       "4  Lisa Simpson: It's like an ox, only it has a h...           254000   \n",
       "\n",
       "   speaking_line  character_id  location_id raw_character_text  \\\n",
       "0           True             9          5.0       Lisa Simpson   \n",
       "1           True             9          5.0       Lisa Simpson   \n",
       "2           True             9          5.0       Lisa Simpson   \n",
       "3           True             9          5.0       Lisa Simpson   \n",
       "4           True             9          5.0       Lisa Simpson   \n",
       "\n",
       "  raw_location_text                                       spoken_words  \\\n",
       "0      Simpson Home                         Maggie, look. What's that?   \n",
       "1      Simpson Home                                  Lee-mur. Lee-mur.   \n",
       "2      Simpson Home                                  Zee-boo. Zee-boo.   \n",
       "3      Simpson Home  I'm trying to teach Maggie that nature doesn't...   \n",
       "4      Simpson Home  It's like an ox, only it has a hump and a dewl...   \n",
       "\n",
       "                                     normalized_text  word_count  \n",
       "0                             maggie look whats that         4.0  \n",
       "1                                    lee-mur lee-mur         2.0  \n",
       "2                                    zee-boo zee-boo         2.0  \n",
       "3  im trying to teach maggie that nature doesnt e...        24.0  \n",
       "4  its like an ox only it has a hump and a dewlap...        18.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T09:55:03.394531Z",
     "start_time": "2019-11-21T09:55:03.390866Z"
    }
   },
   "outputs": [],
   "source": [
    "phrases = df['normalized_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T09:55:20.464260Z",
     "start_time": "2019-11-21T09:55:20.459548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maggie look whats that',\n",
       " 'lee-mur lee-mur',\n",
       " 'zee-boo zee-boo',\n",
       " 'im trying to teach maggie that nature doesnt end with the barnyard i want her to have all the advantages that i didnt have',\n",
       " 'its like an ox only it has a hump and a dewlap hump and dew-lap hump and dew-lap',\n",
       " 'you know his blood type how romantic',\n",
       " 'oh yeah whats my shoe size',\n",
       " 'ring',\n",
       " 'yes dad',\n",
       " 'ooh look maggie what is that do-dec-ah-edron dodecahedron']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T09:58:18.662052Z",
     "start_time": "2019-11-21T09:58:18.624859Z"
    }
   },
   "outputs": [],
   "source": [
    "text = [[c for c in ph] for ph in phrases if type(ph) is str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:02:20.987452Z",
     "start_time": "2019-11-21T10:02:20.985062Z"
    }
   },
   "outputs": [],
   "source": [
    "CHARS = set('abcdefghijklmnopqrstuvwxyz ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:02:26.537462Z",
     "start_time": "2019-11-21T10:02:26.533821Z"
    }
   },
   "outputs": [],
   "source": [
    "INDEX_TO_CHAR = ['none'] + [w for w in CHARS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:02:31.612179Z",
     "start_time": "2019-11-21T10:02:31.607494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['none',\n",
       " 'o',\n",
       " 'l',\n",
       " 'w',\n",
       " 'j',\n",
       " 'd',\n",
       " 'b',\n",
       " 'q',\n",
       " 'c',\n",
       " 'h',\n",
       " 'z',\n",
       " 'n',\n",
       " 'p',\n",
       " 'y',\n",
       " 'g',\n",
       " 'u',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'k',\n",
       " 'f',\n",
       " 's',\n",
       " 'm',\n",
       " 'x',\n",
       " 'a',\n",
       " 't',\n",
       " 'v',\n",
       " 'i']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_TO_CHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:02:38.755397Z",
     "start_time": "2019-11-21T10:02:38.751987Z"
    }
   },
   "outputs": [],
   "source": [
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:02:44.024253Z",
     "start_time": "2019-11-21T10:02:44.019434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'none': 0,\n",
       " 'o': 1,\n",
       " 'l': 2,\n",
       " 'w': 3,\n",
       " 'j': 4,\n",
       " 'd': 5,\n",
       " 'b': 6,\n",
       " 'q': 7,\n",
       " 'c': 8,\n",
       " 'h': 9,\n",
       " 'z': 10,\n",
       " 'n': 11,\n",
       " 'p': 12,\n",
       " 'y': 13,\n",
       " 'g': 14,\n",
       " 'u': 15,\n",
       " 'e': 16,\n",
       " 'r': 17,\n",
       " ' ': 18,\n",
       " 'k': 19,\n",
       " 'f': 20,\n",
       " 's': 21,\n",
       " 'm': 22,\n",
       " 'x': 23,\n",
       " 'a': 24,\n",
       " 't': 25,\n",
       " 'v': 26,\n",
       " 'i': 27}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHAR_TO_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:02:50.741749Z",
     "start_time": "2019-11-21T10:02:50.299822Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:02:55.697715Z",
     "start_time": "2019-11-21T10:02:55.694701Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:03:24.434620Z",
     "start_time": "2019-11-21T10:03:24.430241Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.zeros((len(text), MAX_LEN), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:03:27.829130Z",
     "start_time": "2019-11-21T10:03:24.437130Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    for j, w in enumerate(text[i]):\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:03:31.296239Z",
     "start_time": "2019-11-21T10:03:31.289480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22, 24, 14, 14, 27, 16, 18,  2,  1,  1, 19, 18,  3,  9, 24, 25, 21, 18,\n",
       "         25,  9, 24, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:03:50.404098Z",
     "start_time": "2019-11-21T10:03:50.395414Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.word_embeddings = torch.nn.Embedding(len(INDEX_TO_CHAR), 28)\n",
    "        self.gru = torch.nn.RNN(28, 128, batch_first=True)\n",
    "        self.hidden2tag = torch.nn.Linear(128, len(INDEX_TO_CHAR))\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state\n",
    "\n",
    "    def forward_state(self, sentences, state):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds, state)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:03:58.932028Z",
     "start_time": "2019-11-21T10:03:58.927797Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:04:09.699285Z",
     "start_time": "2019-11-21T10:04:09.585422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(X[0:1])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:05:19.594670Z",
     "start_time": "2019-11-21T10:05:19.588235Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sentence():\n",
    "    sentence = ['h', 'e', 'l', 'l', 'o']\n",
    "    state = None\n",
    "    for i in range(MAX_LEN):\n",
    "        X = torch.Tensor([[CHAR_TO_INDEX[sentence[i]]]]).type(torch.long)\n",
    "        if i == 0:\n",
    "            result, state = model.forward(X)\n",
    "        else:\n",
    "            result, state = model.forward_state(X, state)\n",
    "        prediction = result[0, -1, :]\n",
    "        index_of_prediction = prediction.argmax()\n",
    "        if i >= len(sentence) - 1:\n",
    "            if index_of_prediction == 0:\n",
    "                break\n",
    "        sentence.append(INDEX_TO_CHAR[index_of_prediction])\n",
    "    print(''.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:05:27.757204Z",
     "start_time": "2019-11-21T10:05:27.734554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helloxpssxxaxxxxsxbxxxxxxxbxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"
     ]
    }
   ],
   "source": [
    "generate_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:05:34.594715Z",
     "start_time": "2019-11-21T10:05:34.591095Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T10:08:53.494387Z",
     "start_time": "2019-11-21T10:08:13.161968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 9.855, Train loss: 2.112\n",
      "helloe     toaaa      oaaaa      oaaaa      oaaaa      \n",
      "Epoch 1. Time: 9.099, Train loss: 1.812\n",
      "helloe     tooaaou     tooaaou     tooaaou     tooaaou \n",
      "Epoch 2. Time: 9.748, Train loss: 1.731\n",
      "helloe     toaaahu     toaaahu     toaaahu     toaaahu \n",
      "Epoch 3. Time: 9.362, Train loss: 1.684\n",
      "helloe     toaaahu     toaaahu     toaaahu     toaaahu \n",
      "Epoch 4. Time: 9.409, Train loss: 1.652\n",
      "helloe     tooaahu     tooaahu     tooaahu     tooaahu \n",
      "Epoch 5. Time: 8.897, Train loss: 1.627\n",
      "helloe     tooaahu     tooaahu     tooaahu     tooaahu \n",
      "Epoch 6. Time: 6.931, Train loss: 1.607\n",
      "helloe     tooaaou     tooaahu     taoaahr     tooaahu \n",
      "Epoch 7. Time: 7.292, Train loss: 1.590\n",
      "helloe l   toaaoou d   taaooort     iooaaau    nonetooaohu\n",
      "Epoch 8. Time: 7.161, Train loss: 1.575\n",
      "helloe l   toaaoou d   taaooort     iooaoan     tooaoou\n",
      "Epoch 9. Time: 7.330, Train loss: 1.562\n",
      "helloe l   toaaoou d   taaooort     iooootn     taoooor\n",
      "Epoch 10. Time: 7.322, Train loss: 1.550\n",
      "helloe l   toaaoou d   taaooort     iooootn     thooooe\n",
      "Epoch 11. Time: 6.967, Train loss: 1.539\n",
      "helloe l   toaaoou d   taaooort     iooootn     thooooe\n",
      "Epoch 12. Time: 7.348, Train loss: 1.528\n",
      "helloe l   toaaoou d   taaooort     iooootn     thooooe\n",
      "Epoch 13. Time: 8.702, Train loss: 1.518\n",
      "helloe l   toaaooutd     tooooou     tooooou     tooooo\n",
      "Epoch 14. Time: 8.439, Train loss: 1.509\n",
      "helloe l   toaaooutd     tooooou     tooooou     tooooo\n",
      "Epoch 15. Time: 9.181, Train loss: 1.500\n",
      "helloe l   toaaooutd  none  tooaoou d  nonetoaooo d   taaooor\n",
      "Epoch 16. Time: 9.498, Train loss: 1.492\n",
      "helloe l   toaooout     iooootn     thooooen     tooooo\n",
      "Epoch 17. Time: 9.228, Train loss: 1.484\n",
      "helloe l   toaooout     iooootn     thooooen     tooooo\n",
      "Epoch 18. Time: 8.977, Train loss: 1.476\n",
      "helloe l   toaooout     iooootn     thooooen     tooooo\n",
      "Epoch 19. Time: 9.608, Train loss: 1.469\n",
      "helloe l   toaoooutn nonenone  tnonenoneaooononennonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 20. Time: 8.427, Train loss: 1.462\n",
      "helloe l   toaoooutn nonenone  tnonenoneaooononennonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 21. Time: 7.345, Train loss: 1.455\n",
      "helloe l   toaoooudn nonenone  tnonenoneaooononennonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 22. Time: 6.245, Train loss: 1.448\n",
      "helloe l   toaoooudn nonenone  tnonenoneaooononennonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 23. Time: 6.708, Train loss: 1.442\n",
      "helloe l   toaoooudn nonenone  tnonenoneaooononennonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone\n",
      "Epoch 24. Time: 7.978, Train loss: 1.436\n",
      "helloe l   tottoou   n toooth    ethooaoenndnone    nonetoooo\n",
      "Epoch 25. Time: 6.925, Train loss: 1.430\n",
      "helloe l   tottoou   n toooth    ethooaoenndnone    nonetoooo\n",
      "Epoch 26. Time: 7.363, Train loss: 1.424\n",
      "helloe l   tottoou   nstoooternnone    noneiooootnnnonenone e nonenoneirt\n",
      "Epoch 27. Time: 8.052, Train loss: 1.418\n",
      "helloe l   tottoou   nstoooternnone    noneiooootnnnonenone e nonenoneirt\n",
      "Epoch 28. Time: 9.153, Train loss: 1.413\n",
      "helloe l   tottoou e nstntot e   tntoooo  n nonetootoe n  \n",
      "Epoch 29. Time: 10.032, Train loss: 1.407\n",
      "helloe l n tototh    etfooaoirndnonene  nonenone toononeah  nonenone toonone\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-869f18e20f9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0manswers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINDEX_TO_CHAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-2ede54481017>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mgru_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtag_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(300):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    for i in range(int(len(X) / 100)):\n",
    "        batch = X[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = batch[:, 1:].flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        answers, _ = model.forward(X_batch)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterion(answers, Y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
    "    generate_sentence()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchnlp.samplers.BucketBatchSampler - для сэмплирования данных"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
