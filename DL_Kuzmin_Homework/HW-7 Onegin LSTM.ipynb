{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('onegin.txt', 'r') as f:\n",
    "    d = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneg = d.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = []\n",
    "count = 0\n",
    "for i in oneg:\n",
    "    if i[:2] == '\\t\\t' and i[:4] != '\\t\\t……':\n",
    "        a.append(i[2:])\n",
    "    count += 1\n",
    "    if count % 4 == 0 and a != []:\n",
    "        b.append(' '.join(a))\n",
    "        a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [x.lower() for x in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he мысля гордый свет забавить, вниманье дружбы возлюбя, хотел бы я тебе представить',\n",
       " 'залог достойнее тебя, достойнее души прекрасной, святой исполненной мечты, поэзии живой и ясной,',\n",
       " 'высоких дум и простоты; но так и быть – рукой пристрастной прими собранье пёстрых глав, полусмешных, полупечальных,',\n",
       " 'простонародных, идеальных, небрежный плод моих забав, бессонниц, лёгких вдохновений, незрелых и увядших лет,',\n",
       " 'ума холодных наблюдений и сердца горестных замет.',\n",
       " '«мой дядя самых честных правил, когда не в шутку занемог, он уважать себя заставил и лучше выдумать не мог.',\n",
       " 'его пример другим наука; но, боже мой, какая скука с больным сидеть и день и ночь, не отходя ни шагу прочь!',\n",
       " 'какое низкое коварство полуживого забавлять, ему подушки поправлять, печально подносить лекарство,',\n",
       " 'вздыхать и думать про себя: когда же чёрт возьмёт тебя!»',\n",
       " 'так думал молодой повеса, летя в пыли на почтовых,']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = set('абвгдеёжзийклмнопрстуфхцчшщыьъэюя.,?! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = []\n",
    "for i in text:\n",
    "    line = ''\n",
    "    for j in i:\n",
    "        if j in CHARS:\n",
    "            line = line+j \n",
    "    text2.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' мысля гордый свет забавить, вниманье дружбы возлюбя, хотел бы я тебе представить',\n",
       " 'залог достойнее тебя, достойнее души прекрасной, святой исполненной мечты, поэзии живой и ясной,',\n",
       " 'высоких дум и простоты но так и быть  рукой пристрастной прими собранье пёстрых глав, полусмешных, полупечальных,',\n",
       " 'простонародных, идеальных, небрежный плод моих забав, бессонниц, лёгких вдохновений, незрелых и увядших лет,',\n",
       " 'ума холодных наблюдений и сердца горестных замет.',\n",
       " 'мой дядя самых честных правил, когда не в шутку занемог, он уважать себя заставил и лучше выдумать не мог.',\n",
       " 'его пример другим наука но, боже мой, какая скука с больным сидеть и день и ночь, не отходя ни шагу прочь!',\n",
       " 'какое низкое коварство полуживого забавлять, ему подушки поправлять, печально подносить лекарство,',\n",
       " 'вздыхать и думать про себя когда же чёрт возьмёт тебя!',\n",
       " 'так думал молодой повеса, летя в пыли на почтовых,']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_TO_CHAR = ['none'] + [w for w in CHARS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'none': 0,\n",
       " 'ъ': 1,\n",
       " ' ': 2,\n",
       " 'з': 3,\n",
       " 'щ': 4,\n",
       " '!': 5,\n",
       " 'к': 6,\n",
       " 'д': 7,\n",
       " 'ц': 8,\n",
       " 'й': 9,\n",
       " 'ь': 10,\n",
       " 'и': 11,\n",
       " 'ф': 12,\n",
       " 'х': 13,\n",
       " ',': 14,\n",
       " 'л': 15,\n",
       " 'а': 16,\n",
       " 'с': 17,\n",
       " 'ё': 18,\n",
       " 'б': 19,\n",
       " 'м': 20,\n",
       " 'р': 21,\n",
       " 'о': 22,\n",
       " '?': 23,\n",
       " 'т': 24,\n",
       " 'ш': 25,\n",
       " 'ы': 26,\n",
       " 'е': 27,\n",
       " 'ч': 28,\n",
       " 'я': 29,\n",
       " '.': 30,\n",
       " 'в': 31,\n",
       " 'э': 32,\n",
       " 'ю': 33,\n",
       " 'ж': 34,\n",
       " 'г': 35,\n",
       " 'п': 36,\n",
       " 'у': 37,\n",
       " 'н': 38}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHAR_TO_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros((len(text2), MAX_LEN), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text2)):\n",
    "    for j, w in enumerate(text2[i]):\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2, 20, 26, 17, 15, 29,  2, 35, 22, 21,  7, 26,  9,  2, 17, 31, 27, 24,\n",
       "          2,  3, 16, 19, 16, 31, 11, 24, 10, 14,  2, 31, 38, 11, 20, 16, 38, 10,\n",
       "         27,  2,  7, 21, 37, 34, 19, 26,  2, 31, 22,  3, 15, 33]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.word_embeddings = torch.nn.Embedding(len(INDEX_TO_CHAR), 28)\n",
    "        self.gru = torch.nn.RNN(28, 128, batch_first=True)\n",
    "        self.hidden2tag = torch.nn.Linear(128, len(INDEX_TO_CHAR))\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state\n",
    "\n",
    "    def forward_state(self, sentences, state):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds, state)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 39])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(X[0:1])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence():\n",
    "    sentence = ['м', 'о', 'й', ' ', 'д', 'я', 'д', 'я']\n",
    "    state = None\n",
    "    for i in range(MAX_LEN):\n",
    "        X = torch.Tensor([[CHAR_TO_INDEX[sentence[i]]]]).type(torch.long).to(dev)\n",
    "        if i == 0:\n",
    "            result, state = model.forward(X)\n",
    "        else:\n",
    "            result, state = model.forward_state(X, state)\n",
    "        prediction = result[0, -1, :]\n",
    "        index_of_prediction = prediction.argmax()\n",
    "        if i >= len(sentence) - 1:\n",
    "            if index_of_prediction == 0:\n",
    "                break\n",
    "        sentence.append(INDEX_TO_CHAR[index_of_prediction])\n",
    "    print(''.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мой дядяыыхыыфафзццкццц!цыт ыыыткхцыыззцзлкрыцыыйы?й!ыаццз\n"
     ]
    }
   ],
   "source": [
    "generate_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.005, momentum=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 0.052, Train loss: 3.663\n",
      "мой дядяыыхыыфафзццкццц!цыт ыыыткхцыыззцзлкрыцыыйыой!ыаццз\n",
      "Epoch 100. Time: 0.043, Train loss: 2.663\n",
      "мой дядя   со   нооеенооон        ноооооооон        нооооо\n",
      "Epoch 200. Time: 0.060, Train loss: 2.533\n",
      "мой дядя т по   носолпоролт        поорррррррраа        по\n",
      "Epoch 300. Time: 0.029, Train loss: 2.463\n",
      "мой дядя с по   птпорпоррорнаснаат        порррррррраааа  \n",
      "Epoch 400. Time: 0.027, Train loss: 2.414\n",
      "мой дядя с по   птпррпоррораасноан   т    соропорртрасонаа\n",
      "Epoch 500. Time: 0.070, Train loss: 2.374\n",
      "мой дядяас па    тполпоррррноо оаааи  пр    нороппрросасоо\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-934932ea8dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_passed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(10000):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    for i in range(int(len(X) / 100)):\n",
    "        batch = X[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = batch[:, 1:].flatten()\n",
    "        X_batch = X_batch.to(dev)\n",
    "        Y_batch = Y_batch.to(dev)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        answers, _ = model.forward(X_batch)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterion(answers, Y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    \n",
    "    if ep % 100 == 0:\n",
    "        print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
    "        generate_sentence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Network(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.word_embeddings = torch.nn.Embedding(len(INDEX_TO_CHAR), 28)\n",
    "        self.gru = torch.nn.GRU(28, 128, batch_first=True)\n",
    "        self.hidden2tag = torch.nn.Linear(128, len(INDEX_TO_CHAR))\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state\n",
    "\n",
    "    def forward_state(self, sentences, state):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        gru_out, state = self.gru(embeds, state)\n",
    "        tag_space = self.hidden2tag(gru_out.reshape(-1, 128))\n",
    "        return tag_space.reshape(sentences.shape[0], sentences.shape[1], -1), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(epocha):\n",
    "    for ep in range(epocha):\n",
    "        start = time.time()\n",
    "        train_loss = 0.\n",
    "        train_passed = 0\n",
    "\n",
    "        for i in range(int(len(X) / 100)):\n",
    "            batch = X[i * 100:(i + 1) * 100]\n",
    "            X_batch = batch[:, :-1]\n",
    "            Y_batch = batch[:, 1:].flatten()\n",
    "            X_batch = X_batch.to(dev)\n",
    "            Y_batch = Y_batch.to(dev)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            answers, _ = model.forward(X_batch)\n",
    "            answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "            loss = criterion(answers, Y_batch)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_passed += 1\n",
    "\n",
    "\n",
    "        if ep % 100 == 0:\n",
    "            print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
    "            generate_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_net(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# лосс больше не падает - сеть генерирует отдельные слова. Попробовал ванильную RNN и GRU. Результат сильно не улушился."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
