{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Прочитать про методы оптимизации для нейронных сетей https://habr.com/post/318970/\n",
    "Реализовать самостоятельно логистическую регрессию\n",
    "Обучить ее методом градиентного спуска\n",
    "Методом nesterov momentum\n",
    "Методом rmsprop\n",
    "В качестве dataset'а взять Iris, оставив 2 класса:\n",
    "Iris Versicolor\n",
    "Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import exp, ceil, floor\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(iris.data)\n",
    "y = pd.DataFrame(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['y'] == 1) | (df['y'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(df.y)\n",
    "X = pd.DataFrame(df.drop('y', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.hstack([y_train, X_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вероятностный взгляд. Бинарная классификация\n",
    "Рассмотрим задачу классификации. Предположим, что ответ нашей модели $h_\\theta(x_i)$ получен на основе логистической регрессии ($\\sigma(Wx_i + b)$). Ее значения лежат в диапазоне от 0 до 1, что может быть интерпретировано, как вероятность, что $x_i$ принадлежит positive классу. Если вероятность $< 0.5$ - мы делаем предсказание о принадлежности отрицательному классу, а если $>= 0.5$ - положительному. Следовательно:\n",
    "\n",
    "$$p(y_i = 1 \\vert x_i)  = h_\\theta(x_i)$$\n",
    "$$p(y_i = 0 \\vert x_i) = 1 - h_\\theta(x_i)$$\n",
    "\n",
    "Мы можем соединить это в одно уравнение:\n",
    "\n",
    "$$p(y_i | x_i) = [h_\\theta(x_i)]^{(y_i)} [1 - h_\\theta(x_i)]^{(1 - y_i)}$$\n",
    "\n",
    "Опять-таки из предположения, что наши данные независимы и одинаково распределены перейдем к правдоподобию:\n",
    "\n",
    "$$L(x, y) = \\prod_{i = 1}^{N}[h_\\theta(x_i)]^{(y_i)} [1 - h_\\theta(x_i)]^{(1 - y_i)}$$\n",
    "\n",
    "Точно так же, как в случае MSE, возмьмем логарифм и инвертируем знак. Получим наш loss:\n",
    "\n",
    "$$J = -\\sum_{i=1}^{N} y_i\\log (h_\\theta(x_i)) + (1 - y_i)\\log(1 - h_\\theta(x_i))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(y_train.values).reshape(80,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, weights):\n",
    "    '''Возвращает массив массив вероятностей, что класс == 1'''\n",
    "    z = np.dot(features, weights)\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(features, labels, weights):\n",
    "    '''Реализуем функцию потерь для бинарной классификации со средней абсолютной ошибкой'''\n",
    "    observations = len(labels)\n",
    "    predictions = predict(features, weights)\n",
    "    #Take the error when label=1\n",
    "    class1_cost = -labels*np.log(predictions)\n",
    "    #Take the error when label=0\n",
    "    class2_cost = (1-labels)*np.log(1-predictions)\n",
    "    #Take the sum of both costs\n",
    "    cost = class1_cost - class2_cost\n",
    "    #Take the average cost\n",
    "    cost = cost.sum()/observations\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(features, labels, weights, lr):\n",
    "    '''Реализуем алгоритм градиентного спуска'''\n",
    "    N = len(features)\n",
    "    #1 - Get Predictions\n",
    "    predictions = predict(features, weights)\n",
    "    #2 Transpose features from (200, 3) to (3, 200)\n",
    "    # So we can multiply w the (200,1) cost matrix.\n",
    "    # Returns a (3,1) matrix holding 3 partial derivatives --\n",
    "    # one for each feature -- representing the aggregate\n",
    "    # slope of the cost function across all observations\n",
    "    gradient = np.dot(features.T, predictions - labels)\n",
    "    #3 Take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "    #4 - Multiply the gradient by our learning rate\n",
    "    gradient *= lr\n",
    "    #5 - Subtract from our weights to minimize cost\n",
    "    weights -= gradient\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_boundary(prob):\n",
    "    return 1 if prob >= .5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(preds):\n",
    "    #decision_boundary = np.vectorize(decision_boundary)\n",
    "    return decision_boundary(preds).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, labels, weights, lr, iters):\n",
    "    cost_history = []\n",
    "    for i in range(iters):\n",
    "        weightsold = weights\n",
    "        weights = update_weights(features, labels, weights, lr)\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "        # Log Progress\n",
    "        if i % 1000 == 0:\n",
    "            print (\"iter: \"+str(i) + \" cost: \"+str(cost))\n",
    "            print (weights)\n",
    "        if cost<10**-10:\n",
    "            print (\"Алгоритм сошелся на шаге \"+ str(i))\n",
    "            print (\"iter: \"+str(i) + \" cost: \"+str(cost))\n",
    "            print (weights)\n",
    "            break\n",
    "    return weights, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 cost: 0.6884063930620666\n",
      "[0.00285552 0.00152756 0.00440659 0.00420512]\n",
      "iter: 1000 cost: 0.1571661907314658\n",
      "[ 0.2975576  -0.13422338  1.35471634  1.32351586]\n",
      "iter: 2000 cost: 0.09427132981503857\n",
      "[ 0.1753828  -0.35430905  1.92112384  1.80751898]\n",
      "iter: 3000 cost: 0.06287637757598512\n",
      "[ 0.05767191 -0.48645441  2.34377886  2.12701728]\n",
      "iter: 4000 cost: 0.042602234883608134\n",
      "[-0.04693184 -0.56759438  2.69771733  2.37064004]\n",
      "iter: 5000 cost: 0.027663167611299055\n",
      "[-0.14081719 -0.61775735  3.01052958  2.57057228]\n",
      "iter: 6000 cost: 0.015746033626563037\n",
      "[-0.22652764 -0.64790535  3.2957675   2.7421702 ]\n",
      "iter: 7000 cost: 0.005733099302533717\n",
      "[-0.30597054 -0.66449828  3.56118855  2.89395209]\n",
      "Алгоритм сошелся на шаге 7644\n",
      "iter: 7644 cost: -4.4714437737347625e-06\n",
      "[-0.35447553 -0.66996865  3.72398526  2.98372524]\n"
     ]
    }
   ],
   "source": [
    "W, C = train(features, labels, weights, 0.01, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим адекватность метода на стандартном алгоритме \"из коробки\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28109636, -0.59297763,  2.21267607,  2.38820582]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35447553 -0.66996865  3.72398526  2.98372524]\n"
     ]
    }
   ],
   "source": [
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08787821])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(features, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Реализуем функцию прогнозирования принадлежности к классу\n",
    "def func(W, X):\n",
    "    klass = []\n",
    "    for i in X.values:\n",
    "        sg = (1/(1+exp(W[0]*i[0]+W[1]*i[1]+W[2]*i[2]+W[3]*i[3])))\n",
    "        if sg < 0.5:\n",
    "            a = 2\n",
    "        else: \n",
    "            a = 1\n",
    "        klass.append(a)\n",
    "    return klass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = func(W, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем функцию обновления весов методом Несторов Моментум\n",
    "\n",
    "def update_weights_nesterov_momentum(features, labels, weights, lr, gamma):\n",
    "    '''Реализуем алгоритм градиентного спуска'''\n",
    "    N = len(features)\n",
    "    momentumold = 0\n",
    "    momentum = 0\n",
    "    #1 - Получаем предсказания\n",
    "    predictions = predict(features, weights)\n",
    "    #2 Транспонируем матрицу факторов, так что мы сможем умножить \n",
    "    # So we can multiply w the (200,1) cost matrix.\n",
    "    # Returns a (3,1) matrix holding 3 partial derivatives --\n",
    "    # one for each feature -- representing the aggregate\n",
    "    # slope of the cost function across all observations\n",
    "    gradient = np.dot(features.T, predictions - labels)\n",
    "    #3 Take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "    momentumold = momentum\n",
    "    momentum = momentumold*gamma+ (1-gamma)*gradient\n",
    "    #4 - Multiply the gradient by our learning rate\n",
    "    gradient = gradient*lr+momentum\n",
    "    #5 - Subtract from our weights to minimize cost\n",
    "    weights -= gradient\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nesterov_momentum(features, labels, weights, lr, iters, gamma):\n",
    "    cost_history = []\n",
    "    for i in range(iters):\n",
    "        weightsold = weights\n",
    "        weights = update_weights_nesterov_momentum(features, labels, weights, lr, gamma)\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "        # Log Progress\n",
    "        if i % 1000 == 0:\n",
    "            print (\"iter: \"+str(i) + \" cost: \"+str(cost))\n",
    "            print (weights)\n",
    "        if cost<10**-10 or cost == 0:\n",
    "            print (\"Алгоритм сошелся на шаге \"+ str(i))\n",
    "            print (\"iter: \"+str(i) + \" cost: \"+str(cost))\n",
    "            print (weights)\n",
    "            break\n",
    "    return weights, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 cost: 0.6429820966378591\n",
      "[0.03141073 0.01680318 0.04847249 0.04625634]\n",
      "Алгоритм сошелся на шаге 693\n",
      "iter: 693 cost: -1.5961572965350611e-06\n",
      "[-0.35392491 -0.67049307  3.72362122  2.98445991]\n"
     ]
    }
   ],
   "source": [
    "W, C = train_nesterov_momentum(features, labels, weights, 0.01, 10000, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(features, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = func(W, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# реализуем обновление весов методом RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights_RMSProp(features, labels, weights, lr, gamma, epsilon):\n",
    "    '''Реализуем алгоритм градиентного спуска'''\n",
    "    N = len(features)\n",
    "    momentumold = 0\n",
    "    momentum = 0\n",
    "\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    gradient = np.dot(features.T, predictions - labels)\n",
    "\n",
    "    gradient /= N\n",
    "    momentumold = momentum\n",
    "    momentum = momentumold*gamma+ (1-gamma)*gradient**2\n",
    "    weights = weights - (lr/(np.sqrt(momentum+epsilon))*gradient)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RMSProp(features, labels, weights, lr, iters, gamma, epsilon):\n",
    "    cost_history = []\n",
    "    for i in range(iters):\n",
    "        weightsold = weights\n",
    "        weights = update_weights_RMSProp(features, labels, weights, lr, gamma, epsilon)\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "        # Log Progress\n",
    "        if i % 1000 == 0:\n",
    "            print (\"iter: \"+str(i) + \" cost: \"+str(cost))\n",
    "            print (weights)\n",
    "        if cost<10**-10 or cost == 0:\n",
    "            print (\"Алгоритм сошелся на шаге \"+ str(i))\n",
    "            print (\"iter: \"+str(i) + \" cost: \"+str(cost))\n",
    "            print (weights)\n",
    "            break\n",
    "    return weights, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 cost: 0.6538597348551767\n",
      "[0.03143063 0.03096621 0.03154166 0.03153374]\n",
      "Алгоритм сошелся на шаге 141\n",
      "iter: 141 cost: -0.0004917324427380354\n",
      "[-0.34909885 -0.73513552  3.64428201  3.17744491]\n"
     ]
    }
   ],
   "source": [
    "W, C = train_RMSProp(features, labels, weights, 0.01, 10000, 0.9, 10**-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(features, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = func(W, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Итого: метод Нестерова в 10 раз быстрее обычного градиентного спуска, \n",
    "#метод RMSProp - в 7 раз быстрее метода Нестерова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Далее просьба не проверять - черновые варианты реализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем алгоритм подбора весов логистической регрессии методом градиентного спуска\n",
    "def GradientDescentLogReg(C, data, k):\n",
    "    print('C=%d' %C)\n",
    "    errorAccuracy=0\n",
    "    l, m = data.shape\n",
    "    weights=np.ones(m-1)\n",
    "    distance_euclidean=0\n",
    "\n",
    "    weightsDelta=np.ones(m-1)\n",
    "    for step in range(10000):\n",
    "        oldweightsDelta=weightsDelta\n",
    "        weightsDelta=np.ones(m-1)\n",
    "\n",
    "        for obj in data.values:\n",
    "            y=obj[0]\n",
    "            gradient=y*(1-1/(1+exp(-y*(weights[0]*obj[1]+weights[1]*obj[2]+weights[2]*obj[3]+weights[3]*obj[4]))))\n",
    "            weightsDelta=list(map(lambda w,wd,x: wd+x*gradient-k*C*w,weights,weightsDelta,obj[1:]))\n",
    "\n",
    "        #проверим Евклидово расстояние между соседними шагами, если менее порога, выходим из цикла\n",
    "        distance_euclidean=distance.euclidean(weightsDelta,oldweightsDelta)\n",
    "        if distance_euclidean<errorAccuracy:\n",
    "            print('Дошли до заданной ошибки точности на шаге: %d' % step)\n",
    "            break\n",
    "\n",
    "        weights=list(map(lambda w,wd: w+wd*k/l,weights,weightsDelta))\n",
    "\n",
    "    print('Евклидово расстояние=%.10f' %distance_euclidean)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1\n",
      "Евклидово расстояние=0.0000000000\n"
     ]
    }
   ],
   "source": [
    "W = GradientDescentLogReg(1, data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.05273912057319143,\n",
       " -0.03672944110749239,\n",
       " 0.24227699565417146,\n",
       " 0.1845187338670464]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
