{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Просьба пока не смотреть. Дорабатываю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитать про методы оптимизации для нейронных сетей https://habr.com/post/318970/\n",
    "Реализовать самостоятельно логистическую регрессию\n",
    "Обучить ее методом градиентного спуска\n",
    "Методом nesterov momentum\n",
    "Методом rmsprop\n",
    "В качестве dataset'а взять Iris, оставив 2 класса:\n",
    "Iris Versicolor\n",
    "Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import exp, ceil, floor\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(iris.data)\n",
    "y = pd.DataFrame(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['y'] == 1) | (df['y'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(df.y)\n",
    "X = pd.DataFrame(df.drop('y', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.hstack([y_train, X_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вероятностный взгляд. Бинарная классификация\n",
    "Рассмотрим задачу классификации. Предположим, что ответ нашей модели $h_\\theta(x_i)$ получен на основе логистической регрессии ($\\sigma(Wx_i + b)$). Ее значения лежат в диапазоне от 0 до 1, что может быть интерпретировано, как вероятность, что $x_i$ принадлежит positive классу. Если вероятность $< 0.5$ - мы делаем предсказание о принадлежности отрицательному классу, а если $>= 0.5$ - положительному. Следовательно:\n",
    "\n",
    "$$p(y_i = 1 \\vert x_i)  = h_\\theta(x_i)$$\n",
    "$$p(y_i = 0 \\vert x_i) = 1 - h_\\theta(x_i)$$\n",
    "\n",
    "Мы можем соединить это в одно уравнение:\n",
    "\n",
    "$$p(y_i | x_i) = [h_\\theta(x_i)]^{(y_i)} [1 - h_\\theta(x_i)]^{(1 - y_i)}$$\n",
    "\n",
    "Опять-таки из предположения, что наши данные независимы и одинаково распределены перейдем к правдоподобию:\n",
    "\n",
    "$$L(x, y) = \\prod_{i = 1}^{N}[h_\\theta(x_i)]^{(y_i)} [1 - h_\\theta(x_i)]^{(1 - y_i)}$$\n",
    "\n",
    "Точно так же, как в случае MSE, возмьмем логарифм и инвертируем знак. Получим наш loss:\n",
    "\n",
    "$$J = -\\sum_{i=1}^{N} y_i\\log (h_\\theta(x_i)) + (1 - y_i)\\log(1 - h_\\theta(x_i))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем алгоритм подбора весов логистической регрессии методом градиентного спуска\n",
    "def GradientDescentLogReg(C,data):\n",
    "    print('C=%d' %C)\n",
    "    errorAccuracy=10**-5\n",
    "    weights=[0., 0., 0., 0.]\n",
    "    k=0.1#длина шага\n",
    "    l=data[0].count()#количество элементов в выборке\n",
    "    distance_euclidean=0\n",
    "\n",
    "    weightsDelta=[0., 0., 0., 0.]\n",
    "    for step in range(10000):\n",
    "        oldweightsDelta=weightsDelta\n",
    "        weightsDelta=[0., 0., 0., 0.]\n",
    "\n",
    "        for obj in data.values:\n",
    "            y=obj[0]\n",
    "            gradient=y*(1-1/(1+exp(-y*(weights[0]*obj[1]+weights[1]*obj[2]+weights[2]*obj[3]+weights[3]*obj[4]))))\n",
    "            weightsDelta=list(map(lambda w,wd,x: wd+x*gradient-k*C*w,weights,weightsDelta,obj[1:]))\n",
    "\n",
    "        #проверим Евклидово расстояние между соседними шагами, если менее порога, выходим из цикла\n",
    "        distance_euclidean=distance.euclidean(weightsDelta,oldweightsDelta)\n",
    "        if distance_euclidean<errorAccuracy:\n",
    "            print('Дошли до заданной ошибки точности на шаге: %d' % step)\n",
    "            break\n",
    "\n",
    "        weights=list(map(lambda w,wd: w+wd*k/l,weights,weightsDelta))\n",
    "\n",
    "    print('Евклидово расстояние=%.6f' %distance_euclidean)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1\n",
      "Дошли до заданной ошибки точности на шаге: 506\n",
      "Евклидово расстояние=0.000010\n"
     ]
    }
   ],
   "source": [
    "W = GradientDescentLogReg(1, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим адекватность метода на стандартном алгоритме \"из коробки\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28109636, -0.59297763,  2.21267607,  2.38820582]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08787821])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Реализуем функцию прогнозирования принадлежности к классу\n",
    "def func(W, X):\n",
    "    klass = []\n",
    "    for i in X.values:\n",
    "        sg = (1/(1+exp(W[0]*i[0]+W[1]*i[1]+W[2]*i[2]+W[3]*i[3])))\n",
    "        if sg < 0.5:\n",
    "            a = 2\n",
    "        else: \n",
    "            a = 1\n",
    "        klass.append(a)\n",
    "    return klass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = func(W, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(X, idx):\n",
    "    idx_min = floor(idx)\n",
    "    idx_max = ceil(idx)\n",
    "    if idx_min == idx_max or idx_max >= len(X):\n",
    "        return X[idx_min]\n",
    "    elif idx_min < 0:\n",
    "        return X[idx_max]\n",
    "    else:\n",
    "        return X[idx_min] + (idx - idx_min)*X[idx_max]\n",
    "\n",
    "def EDM(X, gamma, lr=0.25):\n",
    "    Y = []\n",
    "    v = 0\n",
    "    for x in X:\n",
    "        v = gamma*v + lr*x\n",
    "        Y.append(v)\n",
    "    return np.asarray(Y)\n",
    "\n",
    "def NM(X, gamma, lr=0.25):\n",
    "    Y = []\n",
    "    v = 0\n",
    "    for i in range(len(X)):\n",
    "        v = gamma*v + lr*(linear_interpolation(X, i+gamma*v) if i+gamma*v < len(X) else 0)\n",
    "        Y.append(v)\n",
    "    return np.asarray(Y)\n",
    "\n",
    "def SmoothedNM(X, gamma, lr=0.25):\n",
    "    Y = []\n",
    "    v = 0\n",
    "    for i in range(len(X)):\n",
    "        lookahead4 = linear_interpolation(X, i+gamma*v/4)   if i+gamma*v/4      < len(X) else 0\n",
    "        lookahead3 = linear_interpolation(X, i+gamma*v/2)   if i+gamma*v/2      < len(X) else 0\n",
    "        lookahead2 = linear_interpolation(X, i+gamma*v*3/4) if i+gamma*v*3/4    < len(X) else 0\n",
    "        lookahead1 = linear_interpolation(X, i+gamma*v)     if i+gamma*v        < len(X) else 0\n",
    "        v = gamma*v + lr*(lookahead4 + lookahead3 + lookahead2 + lookahead1)/4\n",
    "        Y.append(v)\n",
    "    return np.asarray(Y)\n",
    "\n",
    "def Adagrad(X, eps, lr=2.5):\n",
    "    Y = []\n",
    "    G = 0\n",
    "    for x in X:\n",
    "        G += x*x\n",
    "        v = lr/np.sqrt(G + eps)*x\n",
    "        Y.append(v)\n",
    "    return np.asarray(Y)\n",
    "\n",
    "def RMSProp(X, gamma, lr=0.25, eps=0.00001):\n",
    "    Y = []\n",
    "    EG = 0\n",
    "    for x in X:\n",
    "        EG = gamma*EG + (1-gamma)*x*x\n",
    "        v = lr/np.sqrt(EG + eps)*x\n",
    "        Y.append(v)\n",
    "    return np.asarray(Y)\n",
    "\n",
    "def Adadelta(X, gamma, lr=50.0, eps=0.001):\n",
    "    Y = []\n",
    "    EG = 0\n",
    "    EDTheta = lr\n",
    "    for x in X:\n",
    "        EG = gamma*EG + (1-gamma)*x*x\n",
    "        v = np.sqrt(EDTheta + eps)/np.sqrt(EG + eps)*x\n",
    "        Y.append(v)\n",
    "        EDTheta = gamma*EDTheta + (1-gamma)*v*v\n",
    "    return np.asarray(Y)\n",
    "\n",
    "def AdadeltaZeroStart(X, gamma, eps=0.001):\n",
    "    return Adadelta(X, gamma, lr=0.0, eps=eps)\n",
    "\n",
    "def AdadeltaBigStart(X, gamma, eps=0.001):\n",
    "    return Adadelta(X, gamma, lr=50.0, eps=eps)\n",
    "\n",
    "def Adam(X, beta1, beta2=0.999, lr=0.25, eps=0.0000001):\n",
    "    Y = []\n",
    "    m = 0\n",
    "    v = 0\n",
    "    for i, x in enumerate(X):\n",
    "        m = beta1*m + (1-beta1)*x\n",
    "        v = beta2*v + (1-beta2)*x*x\n",
    "        m_hat = m/(1- pow(beta1, i+1) )\n",
    "        v_hat = v/(1- pow(beta2, i+1) )\n",
    "        dthetha = lr/np.sqrt(v_hat + eps)*m_hat\n",
    "        Y.append(dthetha)\n",
    "    return np.asarray(Y)\n",
    "\n",
    "np.random.seed(413)\n",
    "X = np.arange(0, 300)\n",
    "\n",
    "D_Thetha_spikes = np.asarray( [int(x%60 == 0) for x in X])\n",
    "D_Thetha_rectangles = np.asarray( [2*int(x%40 < 20) - 1 for x in X])\n",
    "D_Thetha_noisy_sin = np.asarray( [np.sin(x/20) + np.random.random() - 0.5 for x in X])\n",
    "D_Thetha_very_noisy_sin = np.asarray( [np.sin(x/20)/5 + np.random.random() - 0.5 for x in X])\n",
    "D_Thetha_uneven_sawtooth = np.asarray( [ x%20/(15*int(x > 80) + 5) for x in X])\n",
    "D_Thetha_saturation = np.asarray( [ int(x % 80 < 40) for x in X])\n",
    "\n",
    "for method_label, method, parameter_step in [\n",
    "                (\"GRAD_Simple_Momentum\", EDM, [0.25, 0.9, 0.975]),\n",
    "                (\"GRAD_Nesterov\", NM, [0.25, 0.9, 0.975]),\n",
    "                (\"GRAD_Smoothed_Nesterov\", SmoothedNM, [0.25, 0.9, 0.975]),\n",
    "                (\"GRAD_Adagrad\", Adagrad, [0.0000001, 0.1, 10.0]),\n",
    "                (\"GRAD_RMSProp\", RMSProp, [0.25, 0.9, 0.975]),\n",
    "                (\"GRAD_AdadeltaZeroStart\", AdadeltaZeroStart, [0.25, 0.9, 0.975]),\n",
    "                (\"GRAD_AdadeltaBigStart\", AdadeltaBigStart, [0.25, 0.9, 0.975]),\n",
    "                (\"GRAD_Adam\", Adam, [0.25, 0.9, 0.975]),\n",
    "            ]:\n",
    "    for label, D_Thetha in [(\"spikes\", D_Thetha_spikes),\n",
    "                            (\"rectangles\", D_Thetha_rectangles),\n",
    "                            (\"noisy sin\", D_Thetha_noisy_sin),\n",
    "                            (\"very noisy sin\", D_Thetha_very_noisy_sin),\n",
    "                            (\"uneven sawtooth\", D_Thetha_uneven_sawtooth),\n",
    "                            (\"saturation\", D_Thetha_saturation), ]:\n",
    "        fig = plt.figure(figsize=[16.0, 9.0])\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        ax.plot(X, D_Thetha, label=\"gradient\")\n",
    "        for gamma in parameter_step:\n",
    "            Y = method(D_Thetha, gamma)\n",
    "            ax.plot(X, Y, label=\"param=\"+str(gamma))\n",
    "\n",
    "        ax.spines['bottom'].set_position('zero')\n",
    "        full_name = method_label + \"_\" + label\n",
    "\n",
    "        plt.xticks(np.arange(0, 300, 20))\n",
    "        plt.grid(True)\n",
    "        plt.title(full_name)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('value')\n",
    "        plt.legend()\n",
    "        plt.show(block=True) #Uncoomment and comment next line if you just want to watch\n",
    "        plt.savefig(full_name)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
